% !TEX TS-program = lualatex
\documentclass[a4paper, 11pt, fleqn, twoside]{scrreprt}
% escapeinside
%\usepackage[gray]{xcolor}
\usepackage[T1]{fontenc}        % T1-Fonts
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{proof} % 
%%http://www.logicmatters.net/resources/ndexamples/proofsty.html
%\usepackage{bussproofs}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{natbib}
\usepackage{abstract}
\usepackage[automark, headsepline]{scrlayer-scrpage}

% Kapitelüberschrift in der Kopfzeile
%\usepackage[automark]{scrpage2} % Schickerer Satzspiegel mit KOMA-Script
%\pagestyle{scrheadings}

% Minted
\usepackage{fontspec}

\setmonofont{Fira Code Regular}
\setmainfont{XCharter Roman}
\newfontfamily{\fallbackfont}{STIX}[Scale=MatchLowercase]
\DeclareTextFontCommand{\textfallback}{\fallbackfont}

\usepackage{newunicodechar}
\newunicodechar{∀}{\textfallback{∀}}
\newunicodechar{≔}{:=}

\usepackage{minted}
\usemintedstyle[Haskell]{trac, fontsize=\small}
\usemintedstyle[Coq]{default, encoding=utf8, fontsize=\small}
\usemintedstyle[Text]{default, fontsize=\small}
%framesep=10pt}
\setmintedinline{style = bw, fontsize=\small}

% Für schönere Tabellen (optional)
% \usepackage{booktabs}           % Netteres Tabellenlayout
% \usepackage{multicol}           % Mehrspaltige Bereiche
% \usepackage{tabularx}           % Tabellen mit fester Breite

% Für Listings
% \usepackage{listings}

% Eine kleine Hilfe für offene Lücken
\newcommand{\todo}[1]{\marginpar{\textbf{TODO:} #1}}
\newcommand{\hinl}[1]{\mintinline{Haskell}{#1}}
\newcommand{\cinl}[1]{\mintinline{Coq}{#1}}

\setlength\partopsep{-\topsep}
\addtolength\partopsep{-\parskip}
\addtolength\partopsep{0.32cm}

\begin{document}
\pagenumbering{roman} % römische Seitenzahlen

\begin{titlepage}
	\vspace*{3cm}
	\centering
	{\huge\bfseries Modelling Call-Time Choice as Effect using Scoped Free 
	Monads\par}
	\vspace{1cm}
	\textbf{Niels Bunkenburg} \par 
	\vspace{6cm}
	\textbf{Master's Thesis} \par
	Programming Languages and Compiler Construction \par
	Department of Computer Science \par
	Kiel University
	\vfill
	Advised by\par
	Priv.-Doz. Dr. Frank Huch \par
	M. Sc. Sandra Dylus
	\vfill
	% Randloses Drucken nicht möglich...
	\tikz[remember picture,overlay] \node[opacity=0.3,inner sep=0pt] at 
	(9.5,-1.5){\includegraphics{img/cau-siegel-1400.png}};
	{\large \today\par}
\end{titlepage}

\newpage
\thispagestyle{empty}
\strut
\newpage

\chapter*{Erklärung der Urheberschaft}
\vspace{2cm}
Ich erkläre hiermit an Eides statt, dass ich die vorliegende Arbeit ohne Hilfe Dritter und ohne Benutzung anderer als der angegebenen Hilfsmittel angefertigt habe.
Aus fremden Quellen direkt oder indirekt übernommene Gedanken sind als solche kenntlich gemacht.
Die Arbeit wurde bisher in gleicher oder ähnlicher Form in keiner anderen Prüfungsbehörde vorgelegt und auch noch nicht veröffentlicht.

\vspace{4cm}
\hspace{1cm} $\overline{~~~~~~~~~~\mbox{Ort, Datum}~~~~~~~~~~}$ \hfill $\overline{~~~~~~~~~~~~~\mbox{Unterschrift}~~~~~~~~~~~~~}$ \hspace{1cm}

\newpage
\mbox{}
\thispagestyle{empty}
\newpage

\begin{abstract}

\end{abstract}

\newpage
\strut
% This is necessary to apply the command that disables lexer errors for Unicode
\begin{minted}{Coq} 
\end{minted}

\begin{minted}{Haskell}
\end{minted}

% Disable highlighting of lexer errors for Unicode
\makeatletter
\expandafter\def\csname PYGdefault@tok@err\endcsname{\def\PYGdefault@bc##1{##1}}
\makeatother

\makeatletter
\expandafter\def\csname PYGtrac@tok@err\endcsname{\def\PYGtrac@bc##1{##1}}
\makeatother

\thispagestyle{empty}
\newpage

% Verzeichnisse
\renewcommand{\contentsname}{Contents}
\tableofcontents   % Inhaltsverzeichnis
%\listoffigures     % Abbildungsverzeichnis
% \listoftables      % Tabellenverzeichnis
% \lstlistoflistings % Abbildungsverzeichnis

\newpage               % Expliziter Umbruch für Seitenzahlen
\pagenumbering{arabic} % arabische Seitenzahlen

% Inhalt

\chapter{Introduction}

\chapter{Preliminaries}

\section{Curry}
Curry \citep{hanus2016curry} is a functional logic programming language based on Haskell.
Its syntax is therefore largely based on Haskell's and many features like pattern matching, polymorphism, higher-order functions and type classes are supported in Curry, too.
Besides its functional part, Curry has logical aspects known from languages like Prolog.
These include free variables and non-determinism, that is, unknown values and multiple values as the result of evaluating the same expression.

Curry programs can be executed using one of many compilers.
Most notable are KiCS2\footnote{\url{https://www-ps.informatik.uni-kiel.de/kics2/}} and PAKCS\footnote{\url{https://www-ps.informatik.uni-kiel.de/~mh/pakcs/}}, which compile Curry code into Haskell and Prolog programs, respectively.

In the following, the three core properties that make up call-time choice are discussed.

\subsection{Non-strictness}
Usually when the evaluation of a subexpression fails, the whole expression fails, too.
This so called strict semantics is the idea behind the evaluation strategy of most modern languages.
Certain aspects of strict languages like conditional branching need to be evaluated non-strictly because otherwise loops would never terminate.
However, it is also possible to give the whole language a non-strict semantics, as evidenced by Haskell and Curry.
This means that an expression may have a value although some subexpressions are not evaluated yet.
Consequently, non-strictness allows defining conceptually infinite data structures like a list of powers of two.

\begin{minted}{Haskell}
evens :: [Int]
evens = 1 : map (2*) evens
\end{minted}

Although this list is infinite and cannot be evaluated wholly, non-strictness allows us to evaluate only the parts that are demanded by the surrounding expressions.

\begin{minted}{Haskell}
λ> take 4 evens
[1,2,4,8]
\end{minted}

\begin{minted}{Haskell}
  take 2 evens
= take 2 (1 : map (2*) evens)
= 1 : take 1 (map (2*) evens)
= 1 : take 1 (map (2*) (1 : (map (2*) evens)))
= 1 : take 1 (2 * 1 : map (2*) (map (2*) evens))
= 1 : 2 : take 0 (map (2*) (map (2*) (1 : map (2*) evens)))
= 1 : 2 : []
= [1, 2]
\end{minted}
\subsection{Sharing}
\subsection{Non-determinism}

\section{Coq}
\label{sec:coqIntro}

\section{Modelling Curry Programs using Monadic Code Transformation}
\begin{itemize}
\item Why is the naive MonadPlus approach not sufficient to model Curry semantic?
\item Motivate usage of monadic data types
\item Introduce explicit sharing
\end{itemize}

Modelling Curry programs in a language like Haskell requires a transformation of non-deterministic code into a semantically equivalent, deterministic program.
First, we have a look at the direct representation of non-determinism used in the KiCS2 implementation as described by \citet{brassel2011kics2}.

\subsection{KiCS2 Approach}
Non-determinism in Curry is not limited to \textit{flat} non-determinism but can occur within components of data structures and anywhere in a computation.
This means that expressing non-determinism via Haskell's list monad is not sufficient to model Curry's non-determinism.
\todo{Example}
Instead, existing data types receive additional constructors that represent failure and the choice between two values.
For example, the extended list data type looks as follows.

\begin{minted}{Haskell}
data List a = Nil | Cons a (List a) | Choice (List a) (List a) | Fail
\end{minted}

Since this transformation adds new constructors, all functions need to cover these cases, too.
The new rules return \hinl{Fail} if the function's argument is a failed computation and distribute function calls to both branches if the argument is a choice.

One issue with this approach is that call-time choice is not implemented yet.
If a choice is duplicated during evaluation, this information cannot be recovered later.
Therefore, each \hinl{Choice} constructor has an additional \hinl{ID} argument that identifies the same choices.
Since each choice needs a fresh ID, functions use an additional \hinl{IDSupply} argument when choices are created.

The evaluation of a non-deterministic value is implemented by transforming the value into a search tree which can be traversed with different search strategies.
In the process, each choice ID's decision is stored and then repeated if the same ID is encountered again.

While this approach is useful when the host language supports laziness and sharing, another approach is necessary to model these effects when they are not built into the language.

\subsection{Modelling Laziness and Sharing}
\label{subsec:monadicLifting}
\citet{fischer2009purely} introduce a monadic representation of non-determinism that supports sharing and non-strict evaluation.
Out of simplicity, the implementation idea is presented in Haskell, similar to the approach of the original authors, using the example of permutation sort.
The algorithm consists  of three components.
Firstly, a function \hinl{insert} that inserts an element non-deterministically at every possible position within a list.

\begin{minted}{Haskell}
insert :: MonadPlus m => a -> [a] -> m [a]
insert x xs = return (x:xs)
      `mplus` case xs of
                []     -> mzero
                (y:ys) -> do zs <- insert x ys
                             return (y:zs)
\end{minted}

The second part is the function \hinl{perm} that inserts the head of a given list into the permutations of the list's tail.

\begin{minted}{Haskell}
perm :: MonadPlus m => [a] -> m [a]
perm [] = return []
perm (x:xs) = do ys <- perm xs
                 zs <- insert x ys
                 return zs
\end{minted}

Finally, the function \hinl{sort} generates permutations and then tests whether they are sorted.

\begin{minted}{Haskell}
sort :: MonadPlus m => [Int] -> m [Int]
sort xs = do ys <- perm xs
             guard (isSorted ys)
             return ys
\end{minted}

The function \hinl{isSorted} compares each element in a list to the next one to determine whether the list is sorted.
When we test this implementation, we can see that the runtime increases significantly when adding even a few elements.

\begin{minted}{Haskell}
λ> sort [9, 8..1] :: [[Int]]
[[1,2,3,4,5,6,7,8,9]]
(0.69 secs)
λ> sort [10, 9..1] :: [[Int]]
[[1,2,3,4,5,6,7,8,9,10]]
(6.67 secs)
λ> sort [11, 10..1] :: [[Int]]
[[1,2,3,4,5,6,7,8,9,10,11]]
(77.54 secs)
\end{minted}

The reason for the factorial runtime is that the implementations is needlessly strict.
A list of length $n$  has $n!$ permutations, all of which are generated when running \hinl{sort}.
This matches our observation above, since adding a tenth element increases the runtime by a factor of 10 and an eleventh element multiplies the runtime of the ten-element list by eleven.

If we consider the implementation of \hinl{isSorted}, we can see that, as soon as the comparison of two elements yields \hinl{False}, the function returns \hinl{False} and does not evaluate the remainder of the list.

\begin{minted}{Haskell}
isSorted :: [Int] -> Bool
isSorted (x:y:zs) = (x <= y) && isSorted (y:zs)
isSorted _        = True
\end{minted}

However, since we use bind to pass permutations from \hinl{perm} to \hinl{isSorted}, each permutation is fully evaluated before it is determined whether the permutation is sorted.
This leads to the complete evaluation of every permutation, which results in an inefficient program.

Similarly, when we consider the Curry example \hinl{head (1 : head [] : [])}, the strictness of our \hinl{MonadPlus} approach shows again.
The corresponding Haskell expression is as follows.

\mint{Haskell}{hd [] >>= \x -> hd (1 : x : [])}

Here \hinl{hd :: MonadPlus a => [a] -> m a} is the lifted \hinl{head} function.
Evaluating the expression in Haskell yields \hinl{mzero}, that is, no result, while Curry returns \hinl{1}.
The reason is the definition of the bind operator.
For example, the monad instance for lists defines bind as \hinl{xs >>= f = concatMap f xs}.
In the expression above, this means that the pattern matching within \hinl{concatMap} evaluates \hinl{hd []} to \hinl{mzero} and thus returns \hinl{mzero}.

The strictness observed in both examples is the motivation for an alternative approach.
The problem with the above implementations is that non-deterministic arguments of constructors need to be evaluated completely before the computation can continue.
Therefore, we would like to be able to use unevaluated, non-deterministic computations as arguments of constructors.

As mentioned before, we can implement this idea by adapting all data types so that they may contain non-deterministic components.

\begin{minted}{Haskell}
data List m a = Nil | Cons (m a) (m (List m a))
\end{minted}

The list data type now has an additional argument \hinl{m} of type \hinl{* -> *} that represents a non-determinism monad.
Instead of fixed constructors like \hinl{Choice}, the monad \hinl{m} determines the structure and evaluation strategy of the non-determinism effect.
Two smart constructors \hinl{cons} and \hinl{nil} make handling the new list type more convenient.

\begin{minted}{Haskell}
nil :: Monad m => m (List m a)
nil = return Nil

cons :: Monad m => m a -> m (List m a) -> m (List m a)
cons x y = return (Cons x y)
\end{minted}

Adapting the permutation sort functions to the lifted data type requires us to replace \hinl{[]} with \hinl{List m} 
However, this is not sufficient because the list itself can be the result of a non-deterministic computation.
Therefore, an additional \hinl{m} is wrapped around every occurrence of \hinl{List}.

\begin{minted}{Haskell}
insert' :: MonadPlus m => m a -> m (List m a) -> m (List m a)
insert' mx mxs = cons mx mxs
  `mplus` mxs >>= \xs -> case xs of
                           Nil         -> mzero
                           Cons my mys -> cons my (insert' mx mys)

perm' :: MonadPlus m => m (List m a) -> m (List m a)
perm' ml = ml >>= \l ->
  case l of
    Nil -> nil
    Cons mx mxs -> insert' mx (perm' mxs)
\end{minted}

Whenever pattern matching occurred in the original definition, we now use bind to extract a \hinl{List} value.
Since this only evaluates flat non-determinism and not non-determinism that occurs in the components, non-strictness is upheld as much as possible.

All functions now take arguments of the same type they return.
Thus, the definition of \hinl{sort} does not need bind in order to pass permutations to \hinl{isSorted}.

\begin{minted}{Haskell}
sort' :: MonadPlus m => m (List m Int) -> m (List m Int)
sort' xs = let ys = perm' xs in
  isSorted' ys >>= \sorted -> guard sorted >> ys
\end{minted}

We are now able to take advantage of \hinl{isSorted}'s non-strict definition.
The implementation generates permutations only if there is a chance that the permutation is sorted, that is, only recursive calls of \hinl{perm} that are demanded by \hinl{isSorted} are executed.

We reconsider the Curry example \hinl{head (1 : head [] : [])}.
Since the \hinl{List} data type now takes monad values as arguments, we can write the example using the smart constructors and a lifted \hinl{head} function as follows.

\begin{minted}{Haskell}
λ> hd' (cons (return 1) (cons (hd' nil) nil))
1
\end{minted}

Because we do not need to use bind to get the result of \hinl{hd' nil}, the expression is not evaluated due to non-strictness and the result is equal to Curry's output.

Data types with non-deterministic components solve the problem of non-strictness because each component can be evaluated individually, instead of forcing the evaluation of the whole term.
Unfortunately, this leads to a problem.
\label{sec:sharingComputations}
When unevaluated components are shared via Haskell's built-in sharing, computations, rather than results, are being shared.
This means that the results can be different each time the computation is evaluated, which contradicts the intuition of sharing.

The solution to this problem is an explicit sharing combinator \hinl{share :: m a -> m (m a)} that allows sharing the results of a computation in a non-strict way.
Here, \hinl{m} is a \hinl{MonadPlus} instance, similar to the monad used in the definition of the data type, that supports sharing.
Thus, \hinl{share} takes a  computation and then returns a computation that returns the result, that is, the shared value.
The reason for this nesting of monad layers is that, in short, the \hinl{share} combinator performs some actions that can be immediately executed by bind (the outer monad layer), while the inner monad layer should only be evaluated when needed.
This is explained in more detail later.
With the explicit sharing operator we can adapt \hinl{perm'} to share the generated permutations in order to achieve non-strictness in combination with sharing.

\begin{minted}{Haskell}
sort' :: MonadPlus m => m (List m Int) -> m (List m Int)
sort' xs = do ys <- share (perm' xs)
              sorted <- isSorted'
              guard sorted
              ys
\end{minted}

The \hinl{share} operator must satisfy certain laws, which we discuss in \autoref{sec:lawsOfSharing}.
The implementation of \hinl{share} is subject of the next chapter.

\chapter{Call-Time Choice modelled in Haskell}
Based on the ideas presented in the last chapter, we now want to model call-time choice, that is, non-strictness, sharing and non-determinism, in Haskell.
We still use \hinl{MonadPlus} to parameterize our programs.
However, instead of, for example, using the list instance to make non-determinism visible, we define an effect functor that can express many different effects, including non-determinism and sharing.
This approach, as introduced by \citet{wu2014effect}, will also be the base of the Coq implementation shown in \autoref{ch:callTimeChoiceCoq}.
\todo{Definition effect}

For the implementation of call-time choice, we want to be able to express different effects within our programs.
However, not every program contains effects.
There are also \textit{pure} programs that have no side-effects besides the computation of a value.
A data type that represents such programs could look as follows.

\begin{minted}{Haskell}
data Void a = Return a
\end{minted}

Here, \hinl{Void} means the absence of effects.

If we consider programs that contain effects, also called \textit{impure}, like, non-determinism, a data type that represents such values could look like the following.

\begin{minted}{Haskell}
data ND a = Return a
          | Fail
          | Choice (ND a) (ND a)
\end{minted}

This data type also has a constructor to model pure values but in addition, there are constructors that represent failed computations and the non-deterministic choice between two values.
We could go on and list data types that model many more effects but the question is: Is it possible to create a data type that, if appropriately instantiated, behaves like the original effect functor?
This would allow us to represent programs with many different effects using one compact data type.

Answering this question requires abstracting the concrete form of effect functors into a general program data type.
As we saw in the examples above, we need a way to represent pure values in a program.
Therefore, the first constructor of our new program data type should be \hinl{Return a} for the type \hinl{a}, that is, the result type of the program.
To model effects like non-determinism, the program is parameterized over effect functors of type \hinl{* -> *} that represent, for example, \hinl{Fail} and \hinl{Choice}.
We call this argument \hinl{sig} because the signature of a program tells us which effects can occur.
So far, programs are defined as \hinl{data Prog sig a = Return a}.
In order do make use of the \hinl{sig} component, we need to add a constructor for impure operations.
The \hinl{ND} data type shows us that effect functors can be defined recursively.
Thus, the constructor for impure programs should be recursive, too, to be able to represent this structure.

\begin{minted}{Haskell}
data Prog sig a = Return a | Op (sig (Prog sig a))
\end{minted}

With this definition of \hinl{Prog}, we are able to represent the original functors by instantiating \hinl{sig} appropriately.
For \hinl{Void}, we already have the \hinl{Return} constructor.
Therefore, the data type we can use with \hinl{Prog} does not need a constructor anymore, that is, \hinl{data Void' a}.

\begin{minted}{Haskell}
VoidProg a = Return a
           | Op (Void' (VoidProg a)) -- Void' has no constructors!
\end{minted}

The type \hinl{Prog Void'} now resembles the original type  \hinl{Void} since the \hinl{Op} constructor  would require a value of type \hinl{Void'}, which we cannot  construct.
\footnote{It is possible to use \hinl{undefined} to create an impure value of type \hinl{Prog Void' a}.
Since this  is not possible in Coq, we do not consider this in the Haskell implementation.}
Only \hinl{Return} can be used to define values, similar to the  original data type.

Similar to \hinl{Void'}, we can define a data type  \hinl{Choice} that represents \hinl{Choice} in combination with \hinl{Prog}.

\label{min:ND}
\begin{minted}{Haskell}
data ND p = Fail | Choice p p
\end{minted}

Again, we can omit the \hinl{Return} constructor because it is  already part of the \hinl{Prog} data type.
For the same reason,  the type variable \hinl{a} has been replaced with the variable \hinl{p}, since \hinl{ND} does not have values as arguments but rather programs that return values.

\begin{minted}{Haskell}
data NDProg a = Return a
              | Op (Choice (NDProg a))
\end{minted}

Since \hinl{Op} applies \hinl{sig} recursively,  this yields the following type, which is equivalent to the original data type.

\begin{minted}{Haskell}
data NDProg a = Return a
              | OpFail
              | OpChoice (NDProg a) (NDProg a)
\end{minted}

We have found a way to model effect functors as instances of the data type \hinl{Prog}, which essentially models a tree with leafs, represented by the \hinl{Return} constructor, and branches that have the form defined by \hinl{sig}.
\todo{Tree structure visualization?}

\section{Free Monads}
\begin{itemize}
\item What are free monads?
\item Why do we use free monads?
\end{itemize}

The data type \hinl{Prog} is better known as the \textit{free monad}.
We saw in the previous chapter that \hinl{Free} can be used to model other data types.
In addition, \hinl{Free} is a monad that can turn any functor into a monad.

We consider, for example, the type \hinl{Free One} where \hinl{data One a = One}.
Here \hinl{a} is a phantom type that we need because \hinl{Free} expects a functor.
The monad instance for \hinl{Free} is as follows.

\begin{minted}{Haskell}
data Free f a = Pure a | Impure (f (Free f a))

instance (Functor f) => Monad (Free f) where
  return = Pure
  Pure x >>= g = g x
  Impure fx >>= g = Impure (fmap (>>= g) fx)
\end{minted}

Since \hinl{One} has only a single, non-recursive constructor \hinl{One}, the only possible impure value is \hinl{Impure One}, whereas the usual \hinl{Return} constructor remains.
If bind encounters the value \hinl{One}, the function \hinl{g} is distributed deeper into the term structure using \hinl{fmap}.
Since \hinl{fmap One = One}, it becomes apparent that the monad constructed by \hinl{Free One} is the \hinl{Maybe} monad.
\todo{Visualization of fmap tree}

Since we want to model different effects in our program, the free monad makes writing programs easier by allowing monadic definitions without defining a separate monad instance for each effect.
\todo{Find more reasons for using free monads}
\todo{Stacking monads does not necessarily yield monads again}
% https://homepages.inf.ed.ac.uk/slindley/papers/handlers.pdf

\section{Modelling Effects}
\begin{itemize}
\item Explanation of the Prog/sig infrastructure
\item ND and state effect implementation 
\end{itemize}
\todo{Split ND into choice and fail instead of one}
In the previous sections the free monad and its ability to represent effect functors was discussed.
The goal of this section is to explore the infrastructure that allows us to combine multiple effects, write effectful programs and compute the result of such programs.

\subsection{Combining Effects}
Firstly, we would like to combine multiple effects.
For this purpose, we use the technique introduced by \citet{swierstra2008} to define a data type that combines the effect functors \hinl{sig1} and \hinl{sig2}.
The infix notation simplifies combining multiple effects via nested applications of \hinl{:+:}.

\begin{minted}{Haskell}
data (sig1 :+: sig2) a = Inl (sig1 a) | Inr (sig2 a)
\end{minted}

For example, the type \hinl{ND :+: One} is a functor that we can use with \hinl{Prog} to define programs that contain non-determinism and partiality as follows.

\begin{minted}{Haskell}
progNDOne :: Prog (ND :+: One) Int
progNDOne = Op (Inl (Choice (Op (Inr One)) (Return 42)))
\end{minted}

In the example \hinl{progNDOne} we define a program that represents the non-deterministic choice between a program whose value is absent and a program that returns \hinl{42}.
The complexity of nesting constructors of \hinl{Prog} and \hinl{:+:} correctly increases quickly for bigger terms.
Therefore, we define a type class that allows us to define such expressions more conveniently.
The class is parameterized over two functors, one of which is a subtype -- regarding \hinl{:+:} -- of the other.

\begin{minted}{Haskell}
class (Functor sub, Functor sup) => sub :<: sup where
  inj :: sub a -> sup a
\end{minted}

We need a few instances of the class \hinl{:<:} to make it useful.
The simplest case is \hinl{sig :<: sig} where want to inject a value of type \hinl{sig a} into the same type.
Since we do not need to modify the value in any way, \hinl{id} is used to define \hinl{inj}.

\begin{minted}{Haskell}
instance Functor sig => sig :<: sig where
  inj = id  
\end{minted}

The next instance covers the case \hinl{sig1 :<: (sig1 :+: sig2)}.
Since we already know that \hinl{sig1} is part of the sum type, we only need to apply the correct constructor of \hinl{:+:}, that is, \hinl{Inl} because \hinl{sig1} is the left argument.

\begin{minted}{Haskell}
instance (Functor sig1, Functor sig2) => sig1 :<: (sig1 :+: sig2) where
  inj = Inl
\end{minted}

The last instance assumes that we can inject \hinl{sig} into \hinl{sig2} and describes how we can inject \hinl{sig} into \hinl{sig1 :+: sig2}.
In this case, we can use \hinl{inj} to receive a value of type \hinl{sig2 a}.
All that remains is a situation similar to the previous instance, where we only need to use the matching constructor to complete the injection.
 
\begin{minted}{Haskell}
instance (Functor sig1, sig :<: sig2) => sig :<: (sig1 :+: sig2) where
  inj = Inr . inj
\end{minted}

These instances allow us to write a polymorphic definition of the function \hinl{inject} which injects constructors depending on the given type of the program.

\begin{minted}{Haskell}
inject :: sig1 :<: sig2 => sig1 (Prog sig2 a) -> Prog sig2 a
inject = Op . inj
\end{minted}

\hinl{inject} can then be used as demonstrated in the following example.

\begin{minted}{Haskell}
λ> inject One :: Prog (One :+: ND) a
Op (Inl One)
λ> inject One :: Prog (ND :+: One) a
Op (Inr One)
\end{minted}

The implementation of the function \hinl{inject} assumes that we can inject \hinl{sig1} into \hinl{sig2}.
This is because \hinl{sig2} is the signature of the returned program and \hinl{sig1} is the type of the effect constructor that we want to inject.
This restriction is justified because, for example, non-deterministic syntax should only appear in a program where \hinl{ND} is part of the signature.
With this part of the infrastructure in place, we can redefine the example \hinl{progNDOne} without using \hinl{Inl} and \hinl{Inr} explicitly.

\begin{minted}{Haskell}
progNDOne' :: Prog (ND :+: One) Int
progNDOne' = inject (Choice (inject One) (Return 42))
\end{minted}

Deriving the appropriate instance of \hinl{:<:} when using \hinl{inject} is, however, not always unambiguous.
The last two instances overlap in situations where \hinl{sig = sig1}.
For example, the example \hinl{inject One :: Prog (One :+: One) a} yields different values with respect to the chosen constructor of \hinl{:<:}, depending on the instance.

\begin{minted}{Haskell}
λ> nothing
Op (Inl One) -- second instance
λ> nothing
Op (Inr One) -- third instance
\end{minted}

This is because the type constraint of \hinl{inject}, in this case \hinl{One :<: (One :+: One)}, matches both the second and third instance.
Haskell does not accept overlapping instances by default, which is why we prioritize one instance via pragmas.
In practice, the different term structure due to \hinl{Inl} and \hinl{Inr} does not influence the evaluation as long as we do not explicitly match for the constructors.
This is ensured by an additional function \hinl{prj} of the type class \hinl{:<:}, which is discussed in the next section.

\subsection{Simplified Pattern Matching}
While the function \hinl{inject} allows us to write programs in a more convenient way, we also need to consider how we can evaluate programs.
The same issue of nested applications of \hinl{Op}, \hinl{Inl} and \hinl{Inr} applies when we want to distinguish different effects via pattern matching.
Thus, we add a second function \hinl{prj} to the type class \hinl{:<:}.

\begin{minted}{Haskell}
class (Functor sub, Functor sup) => sub <: sup where
  inj :: sub a -> sup a
  prj :: sup a -> Maybe (sub a)
\end{minted}

The function \hinl{prj} is a partial inverse to \hinl{inj}.
This means that we can project values of a type \hinl{sup a} into a subtype \hinl{sub a}.
For this reason, the return type of the function is a \hinl{Maybe} type.
Similar to \hinl{inj}, we have to define instances for the same cases as before.

\begin{itemize}
\item For \hinl{sig :<: sig}, we can define \hinl{prj} as \hinl{Just} because we know that every element of the supertype is also an element the subtype.

\item \hinl{sig1 :<: (sig1 :+: sig2)} means that we can return \hinl{Just x} for \hinl{Inl x}.
However, for \hinl{Inr} we need to return \hinl{Nothing} because we cannot, in general, project from \hinl{sig2} to \hinl{sig1}.

\item In the last case \hinl{sig :<: sig2 => sig :<: (sig1 :+: sig2)} we know that we can project from \hinl{sig2} to \hinl{sig}.
Thus, in case of \hinl{Inr x}, where \hinl{x} has the type \hinl{sig2}, we can apply \hinl{prj} to construct a value of appropriate type.
The other case \hinl{prj (Inl _)} is handled by returning \hinl{Nothing}.
\end{itemize}

With the definition of \hinl{prj} and the instances of \hinl{:<:}, we can now define the function \hinl{project} which we can use to make pattern matching more convenient.

\begin{minted}{Haskell}
project :: (sub :<: sup) => Prog sup a -> Maybe (sub (Prog sup a))
project (Op s) = prj s
project _      = Nothing
\end{minted}

Due to the recursive definition of the \hinl{Prog} data type, constructors like \hinl{Choice} have \hinl{Prog} arguments themselves.
Thus, \hinl{sub} is applied to \hinl{Prog sup a} in the return type of the projection.
We can only project effectful values because generally it is not clear which functor we should choose for \hinl{sub} when projecting a \hinl{Return} value.

Finally, we can now inject and project effectful values.
Since \hinl{project} is a partial inverse of \hinl{inject}, the equation \hinl{project (inject x) = Just x} holds for values \hinl{x} of appropriate type, excluding failing computations.
\todo{Does it hold?}
This is demonstrated in the following example.

\begin{minted}{Haskell}
λ> type T = Maybe (ND (Prog (ND :+: One) Int))
λ> project (inject (Choice (Return 42) (Return 43))) :: T
Just (Choice (Return 42) (Return 43))
\end{minted}

Now that we can use \hinl{project} as an abstraction of the concrete term structure regarding \hinl{:<:}, we can write a first function that evaluates a non-deterministic, partial program.

\begin{minted}{Haskell}
evalNDOne :: Prog (ND :+: One) a -> [a]
evalNDOne (Return x) = [x]
evalNDOne p = case project p of
               Just (Choice p1 p2) -> evalNDOne p1 ++ evalNDOne p2
               Just Fail           -> []
               Nothing             -> case project p of
                                        Just One -> []
                                        Nothing  -> []
\end{minted}

When \hinl{evalNDOne} encounters a value \hinl{Return x}, \hinl{x} is returned as a singleton list.
For effectful programs, we can use \hinl{project} to distinguish between the constructors of \textit{one effect at a time}.
The case patterns hold the necessary type information for \hinl{project}.
When the projection returns \hinl{Nothing}, another effect can be matched in a nested case expression.
Since we never need to explicitly match for \hinl{Inl} or \hinl{Inr}, overlapping patterns in the instances of \hinl{:<:} do not affect the evaluation of programs in our model.

Although we have already eliminated \hinl{Inl}, \hinl{Inr} and \hinl{Op} from functions that create or evaluate programs, there can be done even more to simplify programming with effects.
Two language extensions, \hinl{PatternSynonyms} and \hinl{ViewPatterns}, allow us to write definitions like the following.

\begin{minted}{Haskell}
pattern PChoice p q <- (project -> Just (Choice p q))
\end{minted}

View patterns -- the right-hand side of the \hinl{<-}, make pattern-matching for certain cases more compact.
A view pattern consists of a function on the left-hand side of \hinl{->}, that is applied to the value that the pattern is matched against, and a pattern on the right-hand side.
The result of the function call is matched against this pattern and the variables inside the pattern can be used in the definition.
The function \hinl{evalNDOne} can be defined using view patterns in the following way.

\begin{minted}{Haskell}
evalNDOne' :: Prog (ND :+: One) a -> [a]
evalNDOne' (Return x) = [x]
evalNDOne' (project -> Just (Choice p1 p2)) = evalNDOne' p1 ++ evalNDOne' p2
evalNDOne' (project -> Just Fail          ) = []
evalNDOne' (project -> Just One           ) = []
\end{minted}

We cannot use \hinl{(project -> Nothing)} without type annotations as a pattern because this would result in overlapping instances.
However, no effects other than those specified in the signature can occur within the program.
Therefore, the \hinl{Nothing} pattern is not necessary.

The second component of the pattern definition above is the option to define a synonym for more complex patterns.
In this case, we name the view patterns similar to the original constructors of the effects.
While this is necessary for every effect constructor, it allows us to rewrite the definition in the following way.

\begin{minted}{Haskell}
evalNDOne'' :: Prog (ND :+: One) a -> [a]
evalNDOne'' (Return    x) = [x]
evalNDOne'' (PChoice p q) = evalNDOne'' p ++ evalNDOne'' q
evalNDOne'' (PFail      ) = []
evalNDOne'' (POne       ) = []
\end{minted}

Writing programs that evaluate effectful programs is now almost as convenient as simple pattern matching.
Finally, a useful definition for working with programs that have the signature \hinl{f :+: g}, where want to match for \hinl{f} but not \hinl{g}, is as follows.

\begin{minted}{Haskell}
pattern Other s = Op (Inr s)
\end{minted}

Since \hinl{:+:} is right-associative in nested applications, we can match for the left argument effect and conveniently match all remaining effects with \hinl{Other}.


\subsection{Effect Handlers}
\label{subsec:effectHandlers}
For each effect in a program's signature, a \textit{handler} is required.
Handling an effect means transforming a program that contains a certain effect into a program where the effect's syntax does not occur anymore.
However, the syntax is not just removed, but the effect's semantics is applied.
The semantics of an effect is therefore given by its handler.
In the following we discuss handlers for the effects non-determinism and state.

\paragraph{Void Effect}
We begin with the data type for absence of effects, \hinl{Void}.
Due to its definition without constructors, there is no \hinl{Void} syntax that needs to be handled.
The only constructor for programs with the signature \hinl{Void} is \hinl{Return}, which we can handle by returning the argument.
Thus, the handler for \hinl{Void} removes the program layer and is usually applied last, when all other effects have been handled.

\begin{minted}{Haskell}
run :: Prog Void a -> a
run (Return x) = x
\end{minted}

\paragraph{Non-determinism Effect}
We already defined a data type for non-deterministic programs in \autoref{min:ND}.
The \hinl{Choice} constructor did not contain any IDs, which we need for the implementation of call-time choice.
Thus, the revised data type is as follows.

\begin{minted}{Haskell}
data ND p = Fail | Choice (Maybe ID) p p
\end{minted}

Not every non-deterministic choice in a program needs an ID, since IDs slow down the evaluation of choices considerably.
Thus, IDs are optional and only assigned when necessary, that is, when choices are shared.

In the last section, we already defined a function \hinl{evalNDOne} that handles the simple \hinl{ND} type without IDs by returning a list of results, where, for each choice, the result lists are concatenated.
For choices with IDs, however, this is not sufficient.
We begin by transforming the program into a program that returns a tree data type which mirrors the non-determinism structure.
\todo{Keep tree structure?}
 
\begin{minted}{Haskell}
runND :: (Functor sig) => Prog (ND :+: sig) a -> Prog sig (Tree.Tree a)
runND (Return a) = return (Tree.Leaf a)
runND Fail       = return Tree.Failed
runND (Choice m p q ) = do
  pt <- runND p
  qt <- runND q
  return (Tree.Choice m pt qt)
runND (Other op) = Op (fmap runND op)
\end{minted}

Next, we need to memorize the decisions that were made while traversing the choice tree.
For this reason, we define a data type \hinl{Decision} that indicates whether the left or right branch of a choice has been picked before for a particular choice ID.
A \hinl{Memo} is maps IDs to decisions.

\begin{minted}{Haskell}
data Decision = L | R
type Memo = Map.Map ID Decision
\end{minted}

The depth-first traversal of the choice tree is implemented in the function \hinl{dfs}.
The returned list of results is created similar to the approach in \hinl{evalNDOne}, except for the case where a choice has a non-empty ID.
The ID could have appeared in a choice that is closer to the root node of the tree and thus, the choice could have already been decided.
Therefore, we need to look up the ID in the \hinl{Memo}.
If the choice has not been made yet, that is, \hinl{Nothing} is returned, the \hinl{Memo} is updated with \hinl{L} for the left branch and \hinl{R} for the right branch.
The recursive calls then descend into the corresponding branch and will make the same decision for this ID if it occurs again.
If, on the other hand, a decision is returned by the \hinl{lookup} function, the branch of the recursive call is chosen according to the decision.

\begin{minted}{Haskell}
dfs :: Memo -> Tree a -> [a]
dfs mem Failed = []
dfs mem (Leaf x) = [x]
dfs mem (Choice Nothing t1 t2) = dfs mem t1 ++ dfs mem t2
dfs mem (Choice (Just n) t1 t2) =
    case Map.lookup n mem of
      Nothing -> dfs (Map.insert n L mem) t1 
              ++ dfs (Map.insert n R mem) t2
      Just L -> dfs mem t1
      Just R -> dfs mem t2
\end{minted}

The function \hinl{dfs} is called with an empty map and yields the list of results that the choice tree represents.
\todo{Examples}

\paragraph{State Effect}
Stateful computations are an important part of the sharing effect that is presented in \autoref{sec:sharing}.
We begin by defining the syntax of the state effect.
Usually, stateful computations can read the current state with \hinl{get} and set a new state with \hinl{put}.
Thus, the data type needs those two constructors, too.
We add an additional type variable that abstracts the type of values that the state can hold.
The variable \hinl{p} represents the program type as before.

\begin{minted}{Haskell}
data State s p = Get' -- ?
               | Put' -- ?
\end{minted}

Both constructors have an effect on a program, that is, a scope in which the effects are visible.
Thus, both constructors need a program argument \hinl{p}.
For \hinl{Put'}, we can simply add the arguments \hinl{s} for the new state and \hinl{p} for the program in which the new state is set.
The constructor \hinl{Get'}, however, contains the program in a different form, namely a function \hinl{s -> p}.
The reason for this is that, if we were using a simple \hinl{p} argument, the handler would have to somehow replace all \hinl{get}-occurrences of the state with appropriate values.
This would require evaluating the whole program, which would defeat the purpose of preserving non-strictness.
Hence, the program is added to \hinl{get} in the form of a functional expression where the function argument replaces the occurrences of the state that are being read in the program.
The data type for the state effect now looks as follows.

\begin{minted}{Haskell}
data State s p = Get' (s -> p)
               | Put' s p
\end{minted}

The smart constructors for stateful programs are defined by instantiating the program and function arguments appropriately.
For \hinl{get}, this means that we need to supply a function of type \hinl{s -> Prog sig s} since \hinl{p} is \hinl{Prog sig s} in this context.
Conveniently, the \hinl{return} function matches this type and thus, is the initial argument of \hinl{Get'}.
For \hinl{put}, the new state and a program that returns \hinl{()} are supplied to \hinl{Put'} because \hinl{put} does not return any information.

\begin{minted}{Haskell}
get :: (State s :<: sig) => Prog sig s
get = inject (Get' return)

put :: (State s :<: sig) => s -> Prog sig ()
put s = inject (Put' s (return ())
\end{minted}

The choice of initial function arguments might not seem intuitive at first because it is not clear how the remaining program finds its way into the argument of, for example, \hinl{Get'}.
Therefore, we consider an example of the state effect and how the free monad is used to write programs.

\begin{minted}{Haskell}
p :: Prog (State Int :+: Void) Int
p = do put 42
       i <- get
       return (i * 2)
\end{minted}

The program sets a state \hinl{42}, gets the value of the current state and then returns double of that.
The normal form of \hinl{p} can be computed by evaluating the occurrences of bind.
We recall the monad instance for the free monad: bind uses \hinl{fmap} to distribute a function deeper into a term.
Thus, we first define a \hinl{Functor} instance.

\begin{minted}{Haskell}
instance (Functor sig) => Monad (Prog sig) where
  return x = Return x
  Return x >>= f = f x
  Op op >>= f = Op (fmap (>>= f) op)

instance Functor (State s) where
  fmap f (Get' g)   = Get' (f . g)
  fmap f (Put' s p) = Put' s (f p)
\end{minted}

In the case of \hinl{Get'}, we need to apply \hinl{g} to a state in order to obtain a program that we can apply \hinl{f} to.
Thus, we pass the result from \hinl{f} to \hinl{g} via function composition.
For \hinl{Put'}, the state \hinl{s} remains unmodified and the function \hinl{f} is applied to the program argument \hinl{p} of the constructor.

Now we can transform the program \hinl{p} into normal form as follows.

\begin{minted}[fontsize=\footnotesize]{Haskell}
put 42 >>= \_ -> get >>= \i -> return (i * 2)
= inject $ fmap (>>= \_ -> get >>= \i -> return (i * 2)) (Put' 42 (return ()))
= inject $ Put' 42 (get >>= \i -> return (i * 2))
= inject $ Put' 42 (inject $ fmap (>>= \i -> return (i * 2)) (Get' return))
= inject $ Put' 42 (inject $ (Get' (\i -> return (i * 2))))
\end{minted}

\hinl{Op} as well as \hinl{Inl} and \hinl{Inr} constructors are replaced by \hinl{inject} in this example.
The expression is transformed by applying the definitions of bind and \hinl{fmap}.
In the last step, we simplify the expression by applying the left identity monad law, that is, \hinl{(>>= f) . return = f}.

We can now see that the remaining program after \hinl{get}, that is, the \hinl{return} call, has been moved into the argument function of \hinl{Get'}.
The function expects a state and replaces the variables, that were bound to the return value of \hinl{get} in the original program, with the state.

Now that we have seen the definition of stateful program syntax and how the state flows through the program via functions, we can define the handler for the state effect.
Naturally, the handler needs to keep track of the current state, which is the first argument of the function.
Then, the function expects a program that contains state syntax.
Finally, the return type is a program that returns a pair of the current state and a return value.

\begin{minted}{Haskell}
runState :: Functor sig => s -> Prog (State s :+: sig) a -> Prog sig (s, a)
runState s (Return a) = return (s, a)
runState s (Get    k) = runState s (k s)
runState s (Put s' k) = runState s' k
runState s (Other op) = Op (fmap (runState s) op)
\end{minted}

For pure values, the current state and the value inside the \hinl{Return} constructor is returned.
When a \hinl{Get} is encountered, we apply the function argument, which expects a state, to the current state and do a recursive call with the resulting program.
\hinl{Put} is handled by a recursive call where the old state is replaced by the new state while the program stays the same.
Finally, other syntax is handled by using \hinl{fmap} to distribute the handler deeper into the term structure, similar to the other handlers we have seen.

The example program \hinl{p} can now be handled by first calling the handler \hinl{runState} to handle the state effect, followed by \hinl{run} to extract the result from the program structure.

\begin{minted}{Haskell}
λ> run . runState 1 $ p
(42,84)
\end{minted}

As expected, the first component represents the current state, which was set by \hinl{put} to \hinl{42}, while the second component is the result that was returned after multiplying the current state by two.

\subsection{Handling Order}
When multiple effects are part of the signature, the question arises whether running handlers in a different order has an effect on the result.
As an example, we define a handler that does not remove syntax but actually adds state syntax to a non-deterministic program.
The function \hinl{results} keeps the structure of a program intact but adds state syntax that increments the current state by one for each result.

\begin{minted}{Haskell}
results :: (ND <: sig, State Int <: sig) => Prog sig a -> Prog sig a
results (Return x)      = get >>= put . (+ 1) >> return x
results Fail            = fail
results (Choice m p q ) = choiceID m (results p) (results q)
results (Op op)         = Op (fmap results op)
\end{minted}

Now we define a program \hinl{tree} that builds the complete, binary choice tree of height \hinl{x}.
For each call of \hinl{tree}, a choice is made where the current height is either incremented or decremented by one.

\begin{minted}{Haskell}
tree :: (ND <: sig) => Int -> Prog sig Int
tree 0 = return 0
tree x = tree (x - 1) >>= \i -> 
  choice (return $ i + 1) (return $ i - 1)
\end{minted}

Each time choice is called, two new branches are created.
Thus, we expect \hinl{tree x} to have $2^\text{\hinl{x}}$ results.
To see the program in action, we define two handlers.
The difference between \hinl{treeGlobal} and \hinl{treeLocal} is the order of the handlers.
In both cases \hinl{results} is run first, but whereas \hinl{treeGlobal} runs the non-determinism handler before the state handler, the opposite is true for \hinl{treeLocal}.

\begin{minted}{Haskell}

treeGlobal :: (Int, Tree.Tree Int)
treeGlobal = run . runState 0 . runND . results $ tree 2

treeLocal :: Tree.Tree (Int, Int)
treeLocal = run . runND . runState 0 . results $ tree 2
\end{minted}

The types of the definitions already indicate a difference.
While \hinl{treeGlobal} returns a state paired with a tree of results, \hinl{treeLocal} returns a tree of state and result pairs.
In the following, the result of evaluating each handler chain is presented as a visualization of the resulting choice tree.

\vspace{0.32cm}

\begin{minipage}{.465 \linewidth}
\begin{minted}{Haskell}
λ> putStrLn . pretty $ treeGlobal
(4,?
├─── ?
│    ├─── 2
│    └─── 0
└─── ?
     ├─── 0
     └─── -2)
\end{minted}
\end{minipage}
\hfill
\vline
\hfill
\begin{minipage}{.475 \linewidth}
\begin{minted}{Haskell}
λ> putStrLn . pretty $ treeLocal
?
├─── ?
│    ├─── (1,2)
│    └─── (1,0)
└─── ?
     ├─── (1,0)
     └─── (1,-2)
\end{minted}
\end{minipage}

\vspace{0.32cm}

As the name suggests, \hinl{treeGlobal}, that is, handling non-determinism first and state second, evaluates the program with a global state, where each non-deterministic branch shares the same state.
Contrary to that, \hinl{treeLocal} creates an individual state for every non-deterministic branch by handling state syntax first.
While the results are not influenced by the order of handlers in this case, this is not generally the case.

\section{Implementing Scoped Effects}
\label{sec:sharing}
\begin{itemize}
\item How can we implement simple sharing as an effect?
\item What about deep/nested sharing?
\item Examples (exRecList, ...)
\end{itemize}

Although Haskell offers sharing as part of the language, we have seen in \autoref{sec:sharingComputations} that the built-in sharing mechanism does not always work as intended when combined with lifted data types.
Thus, we need to model sharing as an effect using the tools that were presented in the previous section.
There is, however, a difference between sharing and the other effects we have seen so far.
Sharing is not an independent effect since it affects non-deterministic choices.
This means that, depending on the presence of sharing, some choice branches may not be explored.
Therefore, sharing is a \textit{scoped} effect, that is, only a delimited part of the program is affected by the effect.

\citet{wu2014effect} present two ways to define scoped effects.
Firstly, syntax for explicitly marking the begin and end of a scope can be defined.
This leads to a more complicated handler because the begin and end tags can be mismatched in the program and one needs to keep track of the current scope environment.
The second approach uses higher-order syntax, that is, the signature of a program is not just a functor but a function that takes a functor as an argument.
This approach makes it possible to have the scoped program as an argument of the syntax constructor.
In the following, an overview of a  -- initially promising but ultimately incorrect  -- hybrid approach and both options mentioned before is given.

\subsection{Hybrid Implementation}

The idea of the hybrid implementation is a combination of the explicit scoping infrastructure and direct program arguments in the syntax definition that the higher-order implementation uses.
In theory, this has the benefit of simple handlers and scoping via program arguments instead of explicit tags.
Therefore, it seemed worthwhile to explore this approach instead of following one of the options mentioned in the introduction of the section.

Beginning with the definition of the sharing syntax data type, we follow the idea of the higher-order approach and define a single constructor \hinl{Share'} with a program argument that represents the shared program.
Although \hinl{p} is supposed to be only the shared program, the monadic bind structure moves the program that follows the \hinl{Share'} constructor into the argument \hinl{p}
The same happened in \autoref{subsec:effectHandlers} for the program argument of the state effect constructor \hinl{put}.

\begin{minted}{Haskell}
data Share p = Share' p

share :: (Share :<: sig) => Prog sig a -> Prog sig (Prog sig a)
share p = return $ inject (Share' p)
\end{minted}

The return type of \hinl{share} is not just a program but a program that returns a program.
The reason for this is explained later in \autoref{subsec:sharingImplementation}.
For the first implementation of \hinl{share}, this outer program layer is empty and thus created by \hinl{return}.

In order to create an example that showcases the usage of \hinl{share} and the monadic structure, we need a few definitions.
First, we define a non-deterministic coin that returns either \hinl{0} or \hinl{1} and a lifted addition function for programs that return integer results.
Since \hinl{(+)} is a strict function in Haskell and Curry, we can mirror this behavior by binding both program arguments and then adding the results.

\begin{minted}{Haskell}
coin :: (ND :<: sig) => Prog sig Int
coin = choice (return 0) (return 1)

addM :: (Functor sig) => Prog sig Int -> Prog sig Int -> Prog sig Int
addM p q = p >>= \i -> q >>= \j -> return (i + j)
\end{minted}

With these functions defined, we can now use the \hinl{share} operator to add a shared coin to an unshared coin, twice, as shown in the following example.
This corresponds to the Curry code \hinl{let x = coin in (x + coin) + (x + coin)}.

\begin{minted}{Haskell}
exAddSharedCoinTwice :: Prog (Share :+: ND :+: Void) Int
exAddSharedCoinTwice = share coin >>= \fx -> addM (addM fx coin) 
                                                  (addM fx coin)
\end{minted}

\vspace{0.32cm}

\begin{minipage}{.4 \linewidth}
\begin{minted}[escapeinside=||, fontsize=\footnotesize]{Haskell}
< ?|$_\texttt{1}$|
  ├── ?|$_\texttt{2}$|
  │   ├── < ?|$_\texttt{1}$|
  │   │     ├── ?|$_\texttt{2}$|
  │   │     │   ├── 0 > >
  │   │     │   └── 1 > >
  .   .     └── ?|$_\texttt{2}$|
  .   .         ├── 1 > >
  .   .         └── 2 > >
\end{minted}
\begin{center}
Hybrid implementation
\end{center}
\end{minipage}
\hspace{.1 \linewidth}
\vline
\hspace{.1 \linewidth}
\begin{minipage}{.475 \linewidth}
\begin{minted}[escapeinside=||, fontsize=\footnotesize]{Haskell}
< ?|$_\texttt{1}$|
  ├── > ? 
  │     ├── < ?|$_\texttt{1}$|
  │     │     ├── > ? 
  │     │     │     ├── 0
  │     │     │     └── 1
  .     .     └── > ? 
  .     .           ├── 1
  .     .           └── 2
\end{minted}
\begin{center}
Explicit scoping tags
\end{center}
\end{minipage}

\vspace{0.32cm}

The left-hand side tree is generated using the data type \hinl{Share} with a single constructor, while the right-hand side visualizes a data type with two constructors that explicitly delimit the scope.
Subscript numbers represent the ID of a choice.
Although this information is added by a sharing handler we have not defined yet, choice IDs are important in order to understand the consequences of the data type definitions for the sharing effect.

Choice IDs are assigned inside a sharing scope.
When a sharing scope is duplicated due to the monadic structure, the choices inside get the same IDs.
Finally, when the choice tree is evaluated, these choices are linked.
The right-hand side tree shows us that explicit scoping tags allow ending a scope in a program.
For example, the scope around the root choice ends first and then the next scope is opened.
The visualization of the hybrid term shows that all opened sharing scopes are only closed at the end of each branch.
This difference in term structure means that the handler for the hybrid approach never stops assigning IDs to choices because it cannot distinguish the shared program that was initially passed as an argument and the following program that was moved into the argument by the monadic structure.

The hybrid implementation correctly assign the ID \hinl{1} for the choice that immediately follows the beginning of the scope.
This is the shared choice that is defined in \hinl{coin}.
The next choice within the branch originates from the unshared coin and ideally should not receive an ID.
Indeed, the implementation with explicit \hinl{begin} and \hinl{end} tags closes the sharing scope after the first choice and thus, the choice does not receive an ID.
The hybrid implementation, however, cannot stop assigning IDs to choices and thus assigns \hinl{2} to the choice.

In the hybrid implementation, when a new scope is opened, the current scope is overwritten.
For this example, this means that the next choice is labeled with \hinl{1} again, since each scope is associated with an initial state that is copied, too, when the sharing scope is duplicated.
Because there is only one sharing scope in the original program, all occurring scopes are duplicates that were created due to non-determinism.
It is critical that copied sharing scopes behave identical because this ensures that the choices inside the scopes are named the same way, resulting in correct call-time choice behavior.
In the example, however, this leads to a fatal flaw.
Until now, assigning the ID \hinl{2} to the unshared choice below the root choice was unnecessary but not incorrect.
As a consequence of the second sharing scope behaving identical to the first one, the second unshared choice also receives the ID \hinl{2}.
Since we now have two equal IDs within a branch, this means that the second choice with the ID \hinl{2} is linked to the decision of the first choice with the ID \hinl{ID}, that is, the first unshared \hinl{coin} is linked to the second one.

This was not intended in the original program and proves that the hybrid approach is unsuitable for modelling scoped effects and, consequently, sharing.
Interestingly, this approach promisingly passed all example tests and algorithms in both Haskell and Coq.
The flaw was only found while doing the finishing touches on the ID generation algorithm.
This shows that the hybrid approach is not incorrect in its entirety but merely requires some refinement, as shown in the next subsection.

\subsection{Higher-Order Scope Syntax}
\label{subsec:HOscopesyntax}
The higher-order approach described by \citet{wu2014effect} is based on a modified  program data type to represent scoped syntax.
So far, the type variable \hinl{sig} has been a functor that is applied to the program type again.
In the higher-order data type, however, \hinl{sig} is applied to a program functor and a type, which makes it of type \hinl{(* -> *) -> * -> *}.

\begin{minted}{Haskell}
data Prog   sig a = Return a | Op (sig (Prog sig a))
data ProgHO sig a = Return a | Op (sig (Prog sig) a)
\end{minted}

Due to the functor argument of \hinl{sig}, it is now called a higher-order functor.
Based on the new program type and higher-order functors, the existing infrastructure for combining signatures, injecting values and pattern matching can be adapted.
This is not discussed here since we are mostly interested in the the definition of effect data types.
For example, the higher-order version of the sharing effect is defined as follows.

\begin{minted}{Haskell}
data HShare m a = forall x. Share' (m x) (x -> m a)
\end{minted}

Due to the new type of \hinl{sig} in the definition of programs, effect data types have an additional argument now, too.
The single argument \hinl{p} has been replaced by a functor argument \hinl{m} and a type \hinl{a}.
Applying \hinl{m} to \hinl{a} corresponds to the argument \hinl{p} we have seen in the previous effect types.
One advantage of splitting \hinl{p} is that it is now possible to apply \hinl{m} to different types, whereas we were limited to \hinl{p} before.
\citet{wu2014effect} demonstrate that this can be useful, for example, when defining exceptions with \hinl{throw} and \hinl{catch} syntax.
Syntax for \hinl{catch} usually consists of a program where exceptions may occur, a handler for said exceptions and the remaining program.
This structure is very similar to the sharing effect since we would also like to pass the shared program as an argument to the sharing syntax.
However, this was not possible with functor-based program type, as we have seen in the previous subsection.
With higher-order programs, however, we can represent the shared program as an argument of type \hinl{m x} where \hinl{m} represents \hinl{Prog sig} and \hinl{x} the return value of the program.
The remaining program is a continuation function \hinl{x -> m a}that takes the result of the shared program and substitutes the results of all matching calls of \hinl{share}, similar to how the current state is propagated in the program for the state effect.

The purpose of {forall x} lies in adding an independent type variable using the language extension \hinl{ExistentialQuantification}.
In this case, independence means that the variable does not occur on the left-hand side of the definition and thus can be different for two values of the same type.
For example, the following data type has a regular type variable and one introduced by \hinl{forall}.

\begin{minted}{Haskell}
data Test a = forall x. Test x a

instance Functor Test where
  fmap f (Test x a) = Test x (f a)
\end{minted}

With this definition, \hinl{[Test 42 True, Test () False]} is a valid expression of type \hinl{Test Bool}.
When we define a functor instance for \hinl{Test}, the argument \hinl{x} remains unmodified while \hinl{f} is applied to \hinl{a}.
Although in a different form, this applies to the sharing data type as well.
The call of \hinl{fmap}, or rather the higher-order equivalent \hinl{emap}, in the definition of bind is responsible for building the program structure and thus, appends the remaining program to the shared program in the case of the definition we used for the hybrid implementation.
Since \hinl{emap} transforms a value of type \hinl{Share m a} into a \hinl{Share m b}, there is no way to leave one program argument (the shared program) unmodified while applying a function to the other.
For this reason, the additional, independent type variable \hinl{x} is necessary in the definition of the sharing effect data type.

One disadvantage of the higher-order approach is the more complicated infrastructure and effect handlers.
In short, \hinl{Other} cases are harder to handle because the simple \hinl{fmap}-approach does not work anymore.
Additionally, due to the function argument of \hinl{Share'}, the visualization of sharing scopes and programs becomes difficult.
Therefore, we will pursue the explicit scoping syntax approach for the remainder of the Haskell chapter.

\subsection{Explicit Scope Syntax}
\label{subsec:explicit}
The previous subsections have demonstrated that program arguments do not correctly model scopes unless we use higher-order infrastructure.
Thus, an alternative approach is needed.
A well known syntactical structure for delimiting scopes are explicit scope tags in the form of \hinl{begin} and \hinl{end} or brackets.
Following this idea, we split the sharing syntax into two parts.
One constructor marks the beginning of the scope, while the other marks the ending of the scope.

\begin{minted}{Haskell}
data Share p = BShare' p | EShare' p
\end{minted}

Both constructor have programs arguments.
\hinl{BShare'}s argument program contains the scoped program block followed by an \hinl{Eshare'} with the remaining program as an argument.
Similar to the state effect, our smart constructors use \hinl{return ()} as an initial program that is replaced by the actual program when the bind structure is evaluated.

\begin{minted}{Haskell}
begin :: (Share :<: sig) => Prog sig ()
begin = inject (BShare' (return ()))

end :: (Share :<: sig) => Prog sig ()
end = inject (EShare' (return ()))
\end{minted}

For example, the following expression shows a scope that includes the \hinl{Choice'} constructor but not the \hinl{Return} values.

\begin{minted}{Haskell}
inject $ BShare' (inject $ Choice' Nothing 
                                   (inject $ EShare' (Return 0))
                                   (inject $ EShare' (Return 1)))
\end{minted}

Now that we can delimit the scope of the sharing effect, it is time to define the actual sharing operator.


\begin{minted}{Haskell}
share :: (Share :<: sig) => Prog sig a -> Prog sig (Prog sig a)
share p = return $ do begin ; x <- p ; end ; return x
\end{minted}

\hinl{share} wraps \hinl{begin} and \hinl{end} tags around a call of bind that executes the program \hinl{p}.
Then, the result is returned.
One problem of this approach is that sharing tags can be mismatched.
For this reason, sharing syntax should only be accessible by means of the smart constructor \hinl{share}.
Nevertheless, mismatched scoping tags are part of the syntax definition and need to be handled.

Now that we have defined the syntax of the sharing effect with explicit scope constructors, we need to consider how the handler should work.
From the structure of the syntax follows that the handler needs to extract the scoped program between the \hinl{begin} and \hinl{end} tags and then modify the choices that occur inside the scope.
Following this idea, we divide the sharing handler into two parts.
The first part is \hinl{bshare}, a function that waits for a \hinl{begin} tag and then hands over its program argument to \hinl{eshare}, which handles the scope and finally returns the program that follows the scope.
Since this program is now outside of the scope, \hinl{bshare} waits for the next \hinl{begin} tag without modifying any choices.

\begin{minted}{Haskell}
bshare :: (ND <: sig) => Prog (Share + sig) a -> Prog sig a
bshare (Return a) = return a
bshare (BShare p) = eshare p >>= bshare
bshare (EShare p) = error "mismatched Eshare"
bshare (Other op) = Op (fmap bshare op)
\end{minted}

The case of mismatched scoping tags, that is, an \hinl{Eshare} occurring before a \hinl{BShare} has opened a scope, can be handled in Haskell with a run-time error.
In Coq, however, this is not possible.
We could wrap the return type of the function in \hinl{Maybe} to represent mismatched tags, but this makes proofs more cumbersome due to the added case distinction.
A solution to this problem is discussed in the next chapter about modelling call-time choice in Coq.

The second part of the handler handles the scoped program and thus should modify choices in such a way that the program behaves as expected regarding call-time choice.

\begin{minted}{Haskell}
eshare :: (ND <: sig)
       => Prog (Share + sig) a -> Prog sig (Prog (Share + sig) a)
eshare (Return a)     = return (Return a)
eshare (BShare p)     = eshare p
eshare (EShare p)     = return p
eshare Fail           = fail
eshare (Choice _ p q) = choiceID {- ID? -} (eshare p) (eshare q)
eshare (Other op)     = Op (fmap eshare op)
\end{minted}

Pure values are simply returned.
When a \hinl{begin} tag is found, this means that there is a scope within in scope, that is, nested scopes.
In this case, \hinl{eshare} keeps modifying choices because neither the original scope nor the new one has not been closed yet.
Contrary to that, closing tags result in switching back to \hinl{bshare} for the remaining program.
Finally, when a choice is encountered, an ID needs to be created for  \hinl{choiceID}, a function which creates a choice with an explicitly passed ID.
However, this is a problem.

The ID that the choice came with is always \hinl{Nothing} because choices are created without IDs.
It comes to mind that \hinl{eshare} could have a state that is incremented for each encountered choice.
Unfortunately, this would entail that each choice is assigned a different ID, that is, two choices could never have the same ID.
This defeats the purpose of choice IDs because it makes sharing impossible.

Consequently, the main finding from the first attempt to define the sharing handler is that we need to add an identifier to sharing scopes.
This allows linking scopes that were duplicated due to non-determinism in the program and can be used to create choice IDs.
Since the problem of linking scopes is more relevant to the implementation of the sharing effect than scoped effects in general, it is discussed in the next section.

\section{Implementation of Sharing as Effect}
\label{subsec:sharingImplementation}
In this section, the simple implementation of sharing from the previous section is refined into an implementation that models call-time choice correctly.

\subsection{Sharing IDs}
To begin with, we consider the following example that shows why we need to link sharing scopes.

\begin{minted}{Haskell}
exAddSharedCoin :: Prog (Share :+: ND) Int
exAddSharedCoin = share coin >>= \fx -> addM fx fx
\end{minted}

The \hinl{coin} in the addition is shared and thus, the expected result is \hinl{0} and \hinl{2}.
When represented as a tree, the example looks like the following.

\begin{minted}{Haskell}
< ? 
  ├── > < ? 
  │       ├── > 0
  │       └── > 1
  └── > < ? 
          ├── > 1
          └── > 2
\end{minted}

In order to evaluate the example correctly, all choices need to have the same ID.
Since all scopes are copies of the same call to \hinl{share}, the sharing handler needs to behave equally for all scopes and the choices within.
However, this information is lost when the bind structure in the term duplicates the sharing scopes.
Hence, the \hinl{begin} and \hinl{end} tags of the scope receive an ID.
Although it would be sufficient to mark only the \hinl{begin} tags, it makes checking for mismatched tags easier to give \hinl{end} an ID, too.

\begin{minted}{Haskell}
data Share p = BShare' Int p | EShare' Int p
\end{minted}

With this new data type, how do we define the smart constructor \hinl{share}?
There are two options: \hinl{share} either receives an ID as a parameter or the ID is generated inside the function.
The former is much simpler to implement but would entail that the user needs to assign a unique ID to each call of \hinl{share}.
Since it is good practice to hide such implementation-specific details from the user, the second approach of generating an ID within \hinl{share} is the better option.

In order to generate an ID for a sharing scope, we need a state that the ID is derived from.
Again, we have two options.
The state could be implemented on the level of the \textit{modelling} language or the \textit{modelled} language.
The former would mean that all programs would need to be defined within the state monad, which is conceptually similar to the approach of user-defined IDs that are put into the program from the outside.

The latter approach uses the state effect on the \hinl{Prog} level, which was discussed in \autoref{subsec:effectHandlers}.
This means that \hinl{share} itself becomes a complex program instead of a simple smart constructor.
In this case, the ID is generated within the program.

Generally, using the \hinl{Prog} state effect is preferable because it does not require adapting the whole infrastructure to the state monad and it ties in elegantly with the theme of modelling effects.

\begin{minted}{Haskell}
share :: (Share :<: sig, State Int :<: sig) 
      => Prog sig a -> Prog sig (Prog sig a)
share p = return $ do 
  i <- get
  put (i + 1)
  begin i
  x <- p
  end i
  return x
\end{minted}

The signature of the program now needs to support an integer state in order to support sharing syntax.
We still use \hinl{return} to create an empty, outer program layer.
The inner program now contains state syntax that retrieves and increments the current state.
The value from the state is then used as the ID of the sharing scope.

The consequence of the added state code is visualized by means of the initial example \hinl{addSharedCoin}.

\begin{minted}{Haskell}
do fx <- share coin
   addM fx fx
\end{minted}

Inlining the definition of \hinl{share} yields the following program.

\begin{minted}{Haskell}
do fx <- return $ do
     i <- get
     put (i + 1)
     begin i
     x <- coin
     end i
     return x
   addM fx fx -- state code is duplicated!
\end{minted}

Due to the left identity law for bind, \hinl{fx <- return $ ...} acts like a \hinl{let} binding where \hinl{fx} is bound to the program that follows \hinl{return}.
This results in the state code being duplicated in the addition.
Unfortunately, this is not the desired behavior, as the following visualization shows.

\begin{minted}[escapeinside=||]{Haskell}
<0 ? 
   ├── 0> <1 ? 
   │         ├── 1> 0
   │         └── 1> 1
   └── 0> <1 ? 
             ├── 1> 1
             └── 1> 2
\end{minted}

When the state is initialized with \hinl{0}, the first scope receives the ID \hinl{0} and increments the state to \hinl{1} when the state code within the first occurrence of \hinl{fx} is executed.
Then, the second \hinl{fx} is evaluated and the same happens again.
Thus, the ID of the following scope is \hinl{1} for both branches\footnote{In this example, the state handler runs before the non-determinism handler and thus, choice branches have a local state.}.
Since the idea of the added state is to link scopes together, so that duplicated scopes receive the same ID, this approach has failed.
Luckily, just a small modification is needed to fix the problem.
The problem of the current \hinl{share} implementation is that one part of the program -- the state code -- needs to be executed immediately, while the other part -- the shared program -- should only be evaluated if needed.
In the current implementation of \hinl{share}, there is an empty, outer program layer that is evaluated by bind when using \hinl{share}.
The reason for the nested program structure now becomes clear: The outer program layer contains the state code that is executed once when bind evaluates \hinl{share}.

\begin{minted}{Haskell}
do fx <- do -- state code is executed
     i <- get
     put (i + 1)
     return $ do
       begin i
       x <- coin
       end i
       return x
   addM fx fx
\end{minted}

Consequently, all occurrences of the state, that is, the scope IDs, are defined before the shared program is evaluated.
Thus, it does not matter if or where in the program the result of \hinl{share} is evaluated.
This is also reflected in the visualization of the example \hinl{addSharedCoin}.

\begin{minted}{Haskell}
<0 ? 
   ├── 0> <0 ? 
   │         ├── 0> 0
   │         └── 0> 1
   └── 0> <0 ? 
             ├── 0> 1
             └── 0> 2
\end{minted}

\subsection{Sharing Infrastructure}

\subsection{Nested Sharing}
With the current definition of the \hinl{share} operator, simple sharing examples are modelled correctly.
However, there are more complex scenarios that have not been considered yet.
For example, calls of \hinl{share} within a shared expression, that is, nested sharing, leads to incorrect behavior.
We consider the following example of adding the shared result of the addition of a shared coin.

\begin{minted}{Haskell}
exAddSharedCoinNested :: Prog (Share :+: ND) Int
exAddSharedCoinNested = share (share coini >>= \fx -> addM fx fx) >>= 
                          \fy -> addM fy fy
\end{minted}

The problematic part is generating the ID for the inner call of \hinl{share}.
Whereas the outer sharing scope correctly receives the ID \hinl{0} for both occurrences within the term structure, the ID of the inner scope differs.

\begin{minted}{Haskell}
<0 <1 ? 
      ├── 1> <1 ? 
      │         ├── 1> 0> <0 <2 ? 
      .         │               ├── 2> <2 ? 
      .         .               │         ├── 2> 0> 0
      .         .               .         └── 2> 0> 1
\end{minted}

The scope with ID \hinl{0} originate from the outer call of \hinl{share}, while the inner scopes correspond to the nested call.
Both scopes with the ID \hinl{0} should behave identically, including the nested scopes.
However, in the current implementation this is not the case.
When \hinl{fy} is evaluated for the first time, the inner call to \hinl{share} receives the ID \hinl{1}, since state was incremented by the first call.
The following scope with ID \hinl{0} is not affected by this because its ID was assigned together with the first scope.
The second nested scope is not linked to the first one, however, because the state code of both scopes is executed separately.
Thus, the increment operation from running the first nested \hinl{share} affects the second one and the ID \hinl{2} is assigned, although it should have been \hinl{1}.

The problem is this example is therefore that the nested \hinl{share} calls are duplicated but the state is not.
To solve this problem, we can add \hinl{put} to the program before \hinl{x <- p}, so that  nested calls of \hinl{share} in \hinl{p} behave identical if the scope program is duplicated.

\begin{minted}{Haskell}
share :: (Share :<: sig, State Int :<: sig) 
      => Prog sig a -> Prog sig (Prog sig a)
share p = do
  i <- get
  put i + 1
  return $ do
    begin i
    put {- new state? -}
    x <- p
    end i
    return x
\end{minted}

For an example like \hinl{exAddSharedCoinNested}, the new state can be as simple as \hinl{i + 1}.
With the added \hinl{put} syntax, the state within the duplicated scope is no longer different to the state in the original scope.
Hence, the nested scope receives the correct ID.

\begin{minted}{Haskell}
<0 <1 ? 
      ├── 1> <1 ? 
      │         ├── 1> 0> <0 <1 ? 
      .         │               ├── 1> <1 ? 
      .         .               │         ├── 1> 0> 0
      .         .               .         └── 1> 0> 1
\end{minted}

This is not a universal solution, however, since ID clashes can occur in some situations.
When nested sharing is followed by another \hinl{share} call, as in the following example, the IDs inside the nested \hinl{share} and the IDs after the nested share can clash.

\begin{minted}{Haskell}
exAddSharedCoin4 :: Prog (Share :+: ND) Int
exAddSharedCoin4 =
  share (share coin >>= \fx -> addM fx fx) >>=
  \fy -> share coin >>= \fz -> addM fy fz
\end{minted}

The tree shows the scope \hinl{1} wrapped around the duplicated, nested \hinl{share} scopes with ID \hinl{2}.
After that, another scope with ID \hinl{2} follows, although this scope belongs to the shared coin \hinl{fz}.

\begin{minted}{Haskell}
<1 <2 ? 
      ├── 2> <2 ? 
      │         ├── 2> 1> <2 ?
      .         │            ├── 2> 0
      .         .            └── 2> 1
\end{minted}

This clash occurred because nested sharing and repeated sharing have the same namespace when \hinl{put (i + 1)} is used to set the scope state.
In order to make the namespaces unique, one option is to have \hinl{put (i * 2)} in the outer program layer and \hinl{put (i * 2 + 1)} for the inner program layer.
In the adapted syntax tree we can now see that the nested calls have the ID \hinl{2 * 1 + 1 = 3}, while the repeated call received the ID \hinl{2 * 1 = 2}.
Most importantly, the IDs of the nested scopes and the last scope are different now.

\begin{minted}{Haskell}
<1 <3 ? 
      ├── 3> <3 ? 
      │         ├── 3> 1> <2 ? 
      .         │            ├── 2> 0
      .         .            └── 2> 1

\end{minted}

The \hinl{*2/*2+1} approach is used, for example, in the KiCS2 compiler.
It can lead to large numbers very quickly, however, and is not suitable for Coq due to its Peano representation of numbers.
A more elegant solution can be implemented using a pair of integers as state.
This way, one component is incremented in the outer program layer and the other component in the inner layer.

\subsection{Deep Sharing}
The implementation of \hinl{share} from the previous subsection supports nested sharing and top-level non-determinism.
Modelling Curry's call-time choice also includes non-determinism that occurs in components of data types.
Therefore, when a value of a data type with non-deterministic components is shared, the individual components should be shared, too.
Similarly to \autoref{subsec:monadicLifting}, data types need to be lifted so that effectful components can be modelled properly.
Since \hinl{Prog sig} is a monad if \hinl{sig} is a functor, the same monadic transformation works here, too.
We reconsider the following lifted list data type.

\begin{minted}{Haskell}
data List m a = Nil | Cons (m a) (m (List m a))

cons :: Monad m => n a -> n (List n a) -> m (List n a)
cons x xs = return (Cons x xs)

nil :: Monad m => m (List n a)
nil = return Nil
\end{minted}

\paragraph{Handling Effectful Components}
In order to make the existing infrastructure compatible with effectful components of data structures, we need to think about the way handlers work.
Since values of lifted data types are considered pure values, although the components might be effectful, effect handlers do not modify such values, that is, the contained effects are not handled.
Instead of differentiating primitive and complex pure values inside all handlers, we choose a different approach.
For example, we consider the following transformation of a non-deterministic list in Curry syntax.

\begin{minted}{Haskell}
  [0 ? 1, 0 ? 1]
= [0, 0 ? 1] ? [1, 0 ? 1]
= [0, 0] ? [0, 1] ? [1, 0] ? [1, 1]
\end{minted}

Beginning with a list that contains non-deterministic elements, we can move choices from the components to the root of the expression.
In the end, only lists without effectful arguments remain.
The same concept can be transferred to our model.
Before running any handlers, effects need to be moved outside of the components, which is called normal form.
\todo{normal form strictness?}
This concept is formalized in the following type class.

\begin{minted}{Haskell}
class Normalform m a b where
    nf :: m a -> m b
\end{minted}

The parameters \hinl{a} and \hinl{b} are used to adapt the return type.
For example, the function \hinl{nf} can normalize an argument of type \hinl{Prog sig (List (Prog sig) a)} into a value of type \hinl{Prog sig (List Identity a)}.
This means that the effects that were contained in the \hinl{Prog sig} argument of \hinl{List} are moved into the outer program layer, while the inner program layer is replaced with the identity monad.

The instance of \hinl{nf} for lists implements this idea.
Firstly, the list is retrieved from the monadic value using bind, followed by pattern matching.
The empty list cannot be further normalized.
A non-empty list is normalized by recursive calls of \hinl{nf} for the element and the remaining list.
The results need to be retrieved again because the result of \hinl{nf} is a monadic value of the monad \hinl{n}, while \hinl{m} is expected.
Thus, the \hinl{return} statements in the last line move the results into the new monad.
\begin{minted}{Haskell}
instance (Normalform n a b, Monad m, Monad n) =>
    Normalform n (List n a) (List m b) where
    nf mxs = mxs >>= \xs ->
               case xs of
                 Nil -> nil
                 Cons mz mzs -> nf mz  >>= \z ->
                                nf mzs >>= \zs ->
                                   cons (return z) (return zs)
\end{minted}

With \hinl{nf} as a normalization layer between effect handlers and data types with effectful components, we can now evaluate expressions like \hinl{cons coin (cons coin nil)}, as the following choice tree demonstrates.

\begin{minted}{Haskell}
? 
├── ? 
│   ├── [0,0]
│   └── [0,1]
└── ? 
    ├── [1,0]
    └── [1,1]
\end{minted}

This tree represents the transformation in Curry shown above.
For all data types that occur in a program, a lifted version with a \hinl{Normalform} instance needs to be defined.
Primitive types require instances, too, but can be simply defined as \hinl{nf = id} because primitive types cannot contain effectful values.

\paragraph{Sharing Complex Data Types}
At the moment, complex data types like lists can only be shared wholly.
This means that expressions like \hinl{let xs = [0?1] in xs ++ xs} correctly yield \hinl{[0,0]} and \hinl{[1,1]}, but \hinl{let xs = [0?1] in head xs + head xs} is evaluated to all four possible results instead of only \hinl{0} and \hinl{2}, as shown below.

\begin{minted}{Haskell}
<(1,1) (1,1)> ? 
              ├── <(1,1) (1,1)> ? 
              │                 ├── 0
              │                 └── 1
              └── <(1,1) (1,1)> ? 
                                ├── 1
                                └── 2
\end{minted}

The sharing scopes are opened correctly but close immediately without including the choices.
To understand how the empty scopes are created, we have a look at a simplified example where \hinl{head} occurs only once.
For further simplification, the \hinl{share} implementation without IDs is used.

\begin{minted}{Haskell}
  share (cons coin nil) >>= headM
= (return $ do begin; x <- (cons coin nil); end; return x) >>= headM
= headM $ do begin; x <- (cons coin nil); end; return x
= headM $ do begin; end; return (Cons coin nil)
= do begin; end; headM (return (Cons coin nil))
= do begin; end; coin
\end{minted}

Since \hinl{x <- (cons coin nil)} is inside the scope but \hinl{return x} is outside, this step moves the choice contained inside the list out of the sharing scope.
For the previous example of adding the list's head twice, the last line would end with \hinl{addM coin coin}, which explains why no sharing is present.
What is missing here is deep sharing, that is, sharing of the individual components of the list, so that the decision of the coins are linked.

Deep sharing is realized similar to the explicit-sharing library\footnote{http://hackage.haskell.org/package/explicit-sharing-0.9} which implements the approach of \citep{fischer2009purely} presented in \autoref{sec:sharingComputations}.
At its core, deep sharing is implemented via a type class \hinl{Shareable} that all data types with shareable components need to implement.

\begin{minted}{Haskell}
class Shareable m a where
  shareArgs :: Monad n 
            => (forall b. Shareable m b => m b -> n (m b))
            -> a -> n a
\end{minted}

Although \hinl{shareArgs} is parameterized over a function that generalizes the type of the sharing operator, it is used only with \hinl{share} in this model.
Similar to \hinl{share}, the function \hinl{shareArgs} adds a monad layer to its input.
\todo{Why?}

When it comes to instances for types like lifted lists, the implementation is straight-forward.
The empty list does not need to be shared.
For non-empty lists, the function \hinl{f}, that is, \hinl{share}, is applied to the components.
Then the result is retrieved using bind and a list is constructed again.
The additional monad layer required by the function type is implemented using \hinl{cons}, since the function is a smart constructor for a program that returns a list.

\begin{minted}{Haskell}
instance (Shareable m a) => Shareable m (List m a) where
    shareArgs f Nil = nil
    shareArgs f (Cons mx mxs) = do mz  <- f mx
                                   mzs <- f mxs
                                   cons mz mzs
\end{minted}

With the implementation of deep sharing by means of \hinl{shareArgs}, we can finally define a sharing operator that covers nested choices, repeated sharing, nested sharing and deep sharing.

Nested choices, that is, multiple choices within one sharing scope, is implemented as part of the handler, which is discussed in the next section.

Repeated sharing required adding an ID and state code to distinguish different scopes.
IDs are also required to link duplicated sharing scopes, so that they behave identically.
Nested sharing required adding a \hinl{put} statement to the sharing scope, so that nested calls of \hinl{share} have a defined state to work with.
In addition, it became clear that the namespace that supplies IDs for nested sharing needs to be distinct from the supply for repeated sharing, since the same IDs can otherwise be assigned unintentionally.

Lastly, we added deep sharing by defining type classes for normalization and sharing of components.
The former moves effects from inside a complex data type to the root of the expression, so that handlers do not need to consider complex data types themselves.
The latter defines a function \hinl{shareArgs} that allows us to not only share whole terms but also the individual components.
The implementation of \hinl{share} now looks as follows.

\begin{minted}{Haskell}
instance (Share <: sig, State (Int, Int) <: sig, ND <: sig) 
          => Sharing (Prog sig) where
  share p = do
    (i, j) <- get
    put (i + 1, j)
    return $ do
      begin (i,j)
      put (i, j + 1)
      x <- p
      x' <- shareArgs share x
      end (i,j)
      return x'
\end{minted}

The ID supply is implemented using a state with two components which are incremented depending on the program layer.
The outer layer, which is responsible for repeated sharing, increments the first component, while the second component is incremented in the inner program layer, which affects nested sharing.

We can observe the effect of \hinl{shareArgs} in the same example as before.

\begin{minted}[escapeinside=||]{Haskell}
 share (cons coin nil) >>= headM
= (return $ do begin; x <- (cons coin nil); 
   x' <- shareArgs share x; end; return x') >>= headM
= headM $ do begin; 
   x' <- shareArgs share (Cons coin nil); end; return x'
= headM $ do begin; 
   x' <- (share coin >>= \mz -> 
          share nil  >>= \mzs -> cons mz mzs); end; return x'
= headM $ do begin; 
   x' <- (share coin >>= \mz -> cons mz nil); end; return x'
= headM $ do begin; end; (share coin >>= \mz -> cons mz nil)
= do begin; end; (share coin >>= \mz -> headM (cons mz nil))
= do begin; end; share coin >>= id
\end{minted}

The result still shows an empty scope from sharing the whole list.
There is a difference, however, in the last part of the expression.
Whereas \hinl{share} without deep sharing resulted in a simple coin, adding \hinl{shareArgs} wraps the coin in another call of \hinl{share}.
Thus, the choice is shared correctly and the \hinl{share} operator behaves as expected.

\subsection{Sharing Handler}
The previous sections were focused on defining a program that models the different aspects of sharing syntactically, that is, scopes with the correct IDs should appear at the correct positions.
What happens inside those scopes has not been discussed in detail, yet.
Hence, this section focuses on handling the sharing effect.

\begin{minted}{Haskell}
runShare :: (ND :<: sig) => Prog (Share + sig) a -> Prog sig a
runShare (Return a)   = return a
runShare (BShare i p) = nameChoices [trip i 0] p
runShare (EShare _ p) = error "runShare: mismatched EShare"
runShare (Other op)   = Op (fmap runShare op)
\end{minted}

Beginning with the top-level handler, there is not much of a difference to the first implementation of the handler in \autoref{subsec:explicit}.
Although the structure is the same, the function \hinl{nameChoices} that handles the program inside the scope now has an additional argument of type \hinl{[Scope]}.
A scope is a triple of integers where the first two digits represent the ID of a scope and the last digit is a counter.
The function \hinl{trip} is a smart constructor for constructing triples from an ID and an initial counter value.

When a program inside a scope should be handled, the function \hinl{nameChoices} takes over.
The signature is the same as for \hinl{runShare} except for a list of scopes.
This list represents the the current scope environment, that is, how many scopes surround the current program.
The third component of a scope becomes important when a choice is encountered.

\begin{minted}{Haskell}
nameChoices :: (ND :<: sig)
            => [Scope] -> Prog (Share + sig) a -> Prog sig a
nameChoices [] _ = error "nameChoices: missing scope"
nameChoices scopes@(i@(l,r,next):scps) prog =
  case prog of
    Return a     -> return a
    BShare i p   -> nameChoices (trip i 0 : scopes) p
    EShare i p   -> checkScope i scopes p
    Fail         -> fail
    Choice _ p q -> let f = nameChoices (inc i : scps)
                    in choiceID (Just i) (f p) (f q)
    Other op     -> Op (fmap (nameChoices scopes) op)
\end{minted}

The ID of a scope is not enough to assign an ID to a choice because multiple choices can occur within the same scope.
Thus, each scope has a counter that is incremented with the function \hinl{inc} when a choice has been assigned an ID, so that the next choice will receive an different ID.
When a scope inside a scope is found, \hinl{nameChoices} continues handling the program but the ID the of the scope is added to the environment.
Ending a scope is performed by the function \hinl{checkScopes} that is passed the ID of the ending tag, the scope environment and the remaining program.

\begin{minted}{Haskell}
checkScope :: (ND :<: sig)
           => SID -> [Scope] -> Prog (Share + sig) a -> Prog sig a
checkScope i scopes p =
  case scopes of
    []             -> error "checkScope: mismatched EShare"
    [(l,r,_)]      -> if (l,r) == i
                        then runShare p
                        else error "checkScope: wrong scope"
    ((l,r,_):scps) -> if (l,r) == i
                        then nameChoices scps p
                        else error "checkScope: crossing scopes"
\end{minted}

There are three cases to distinguish when ending a scope.
Firstly, the scope environment could be empty, that is, no scope has been opened.
Since closing tags are supposed to follow opening tags, this is an error.

Secondly, the scope environment can have only one surrounding scope.
In this case, the ID of the ending tag is checked against the current scope from the environment.
If it matches, we leave the scope and let \hinl{runShare} handle the remaining program.
If the tags do not match, this is an error.

Thirdly, the environment can contain more than one open scopes.
Similar to the previous case, the tag IDs are compared.
This time, matching tags means that we are still inside a scope.
The current scope is left by removing the head element of \hinl{scopes} and \hinl{nameChoices} handles the remaining program.
Here it becomes clear why we need to memorize a counter for each scope: When a nested scope interrupts handling the current scope, we must not begin counting from some initial value again after the nested scope is handled.
Otherwise, the first choice of the scope and the first choice after the nested scope would receive the same ID.

\section{Examples}

As an example of a more complex program that makes use of explicit sharing, the implementation of permutation sort shown in \autoref{subsec:explicit} is adapted.
Conveniently, the second implementation is parameterized over instances of \hinl{MonadPlus} and uses the same lifted data types that are used to implement deep sharing.
Thus, we only need to add explicit sharing to the \hinl{sort} function.

\begin{minted}{Haskell}
sort :: (MonadPlus m, Sharing m) => m (List m Int) -> m (List m Int)
sort l = do
  xs <- share (perm l)
  b <- isSorted xs
  guard b
  xs
\end{minted}

Since the function is already generalized over instances of \hinl{MonadPlus}, explicit sharing is added as a type constraint by means of the class \hinl{Sharing}.
The only function defined by \hinl{Sharing} is the sharing operator \hinl{share}, which depends on an instance of \hinl{Shareable}, that is, the function \hinl{shareArgs} for deep sharing must be defined.

\begin{minted}{Haskell}
class MonadPlus s => Sharing (s :: * -> *) where
    share :: Shareable s a => s a -> s (s a)
\end{minted}

When comparing the runtime of the explicit sharing implementation with the naive, strict approach, there is considerable overhead generated by the lifted data type and effect handlers.
Compared to 0.69 seconds for sorting a list of nine elements using the list monad, the same list now takes over three minutes to sort.

\begin{minted}{Haskell}
λ> testSort [7,6..1]
[1,2,3,4,5,6,7]
(2.56 secs)
λ> testSort [8,7..1]
[1,2,3,4,5,6,7,8]
(20.01 secs)
λ> testSort [9,8..1]
[1,2,3,4,5,6,7,8,9]
(196.08 secs)
\end{minted}

However, there is one case where the explicit-sharing implementation is much faster.
When the \hinl{isSorted} predicate is replaced by a constant function that returns \hinl{False}, lists of any length are "sorted" in constant time, while the list monad implementation still generates all permutations of the input list.
Thus, the explicit-sharing implementation models non-strictness correctly.
Since the resulting lists are indeed sorted, the issue of incoherent sharing mentioned in \autoref{sec:sharingComputations} does not affect this implementation, either.
The higher-order implementation is faster than the implementation with explicit scoping tags, presumably because less pattern matching is occurring due to the single sharing constructor, but sorting a list of nine elements still takes just over two minutes.

As another example, the idea of using sorting algorithms and a non-deterministic predicate to generate permutations introduced by \citet{Christiansen2016allsorts} is implemented for Quicksort.
In order to incorporate sharing into the implementation, we use the function \hinl{partitionM} that splits a list into a pair of lists, depending on whether the elements fulfill a predicate or not.
The result is shared and then accessed via lifted versions of the functions \hinl{fst} and \hinl{snd}.

\begin{minted}{Haskell}
quicksortM :: (Sharing m, MonadPlus m) 
           => (m Int -> m Int -> m Bool) 
           -> m (List m Int) -> m (List m Int)
quicksortM mp mxs = mxs >>=
  \xs -> case xs of
           Nil -> nil
           Cons my mys ->
             do p <- share (partitionM (mp my) mys)
                appM (appM (quicksortM mp (first p)) (cons my nil)) 
                     (quicksortM mp (second p))
\end{minted}

When \hinl{quicksortM} is called with the non-deterministic predicate \hinl{\_ _ -> coin}, the function returns all $n!$ permutations for a list of length $n$.
The Quicksort algorithm is interesting because even a small input list like \hinl{[1..4]} generates many sharing scopes.
When observing the IDs of scopes that are generated, up to ten levels of nested and repeated sharing occur for a list of four elements.
This leads to one reason for the lacking performance of the implementation, which can be observed by adding following line to the handler of the sharing effect.

\begin{minted}{Haskell}
runShare (BShare _ (EShare _ p)) = trace "empty scope" (runShare p)
\end{minted}

While computing the permutations of a four-element list, the output \hinl{empty scope} appears 32,010 times, while only 111 choices are assigned an ID.
One big issue of the implementation is the creation of empty sharing scopes by \hinl{shareArgs}.
Since deep sharing is not demand-driven, a lot of sharing scopes are created preemptively.
In the example, this accounts for roughly 25,000 empty scopes.
The remaining empty scopes can be attributed to the monadic structure that sometimes moves the argument of \hinl{share} outside of the sharing scope, as seen in the previous section.

Nevertheless, instead of a highly optimized implementation, the goal of this thesis is to model Curry's call-time choice correctly in both Haskell and Coq for the purpose of reasoning about programs.
In the following chapter, the current model is implemented in Coq.



\chapter{Call-Time Choice modelled in Coq}
\label{ch:callTimeChoiceCoq}
The goal of this chapter is to transfer one of the  Haskell implementation approaches of the call-time choice model to Coq.
Before implementing a specific approach, the obstacles that Coq's more restrictive language entails are discussed.
We begin with the data structure \hinl{Prog}, that is, the free monad, which allows us to model programs with effects of type \hinl{sig} and results of type \hinl{a}.
In Haskell, the data type looks as follows.

\begin{minted}{Haskell}
data Prog sig a = Return a | Op (sig (Prog sig a))
\end{minted}

The direct translation of the definition to Coq looks very similar to the Haskell version, aside from renaming and the explicit constructor types.

\begin{minted}{Coq}
Fail Inductive Free F A :=
| pure : A -> Free F A
| impure : F (Free F A) -> Free F A.
\end{minted}

However, the definition is rejected by Coq upon loading the file with the following error message.

\begin{minted}[fontsize=\footnotesize]{Coq}
Non-strictly positive occurrence of "Free" in "F (Free F A) -> Free F A".
\end{minted}

Non-strictly positive occurrence is the main challenge when modelling effects in Coq.
The reason for this error is explained in the next section.

\section{Non-strictly Positive Occurrence}
\begin{itemize}
\item What does non-strictly positive occurrence mean?
\item Motivation for usage of containers
\end{itemize}

In \autoref{sec:coqIntro}, we learned that Coq distinguishes between non-recursive definitions and functions that use recursion.
The reason for this is that Coq checks functions for termination, which is an important part of Coq's proof logic.
To understand why functions must always terminate in Coq, we consider the following function.

% https://www.di.ens.fr/~zappa/teaching/coq/ecole11/summer/lectures/lec9.pdf
\begin{minted}{Coq}
Fail Fixpoint loop (x : unit) : A := loop x.
\end{minted}

The function receives an argument \mintinline{Coq}{x} and calls itself with the same argument.
Since this function obviously never terminates, the result type \mintinline{Coq}{A} is arbitrary.
In particular, we could instantiate \mintinline{Coq}{A} with \mintinline{Coq}{False}, the false proposition.
The value \mintinline{Coq}{loop tt : False} could be used to prove anything, according to the principle of explosion.
For this reason, Coq requires all recursive functions to terminate provably.

Returning to the original data type, what is link between \mintinline{Coq}{Free} and termination?
It is well known that recursion can be implemented in languages without explicit recursion syntax by means of constructs like the Y combinator or the data type \mintinline{Coq}{Mu} for type-level recursion.

\begin{minted}{Coq}
Fail Inductive Mu A := mu : (Mu A -> A) -> Mu A.
\end{minted}

\mintinline{Coq}{Mu} is not accepted by Coq for the same reason as \mintinline{Coq}{Free}: non-strictly positive occurrence of the respective data type.
The problematic property of non-strictly positive data types is that the type occurs on the left-hand side of a constructor argument's function type.
This would allow general recursion and thus, as described above, make Coq's logic inconsistent.

In case of \mintinline{Coq}{Free}, the non-strictly positive occurrence is not as apparent as before because the constructors do not have functional arguments.
However, \mintinline{Coq}{F} is being applied to \mintinline{Coq}{Free F A}.
If \mintinline{Coq}{F} has a functional argument with appropriate types, the resulting type becomes non-strictly positive, as shown below.

\begin{minted}{Coq}
Definition Cont R A := (A -> R) -> R.

(* Free (Cont R) *)
Fail Inductive ContF R A :=
| pureC   : A -> ContF R A
| impureC : ((ContF R A -> R) -> R) -> ContF R A.
\end{minted}

In the type of \mintinline{Coq}{impureC} contains a non-strictly positive occurrence of \mintinline{Coq}{ContF R A}.
Consequently, Coq rejects \mintinline{Coq}{Free} because it is not guaranteed that no instance violates the strict positivity requirement.
Representing the \mintinline{Coq}{Free} data type therefore requires a way to restrict the definition to strictly positive data types.
One approach to achieve this goal is described in the next section.

\section{Containers}

\begin{itemize}
\item How do containers work?
\item How do we translate effect functors into containers?
\end{itemize}

Containers, as introduced by \citet{Abbott2005containers}, are an abstraction of data types that store values, with the property that only strictly positive functors. can be modelled as a container.
This will allow us to define a version of \cinl{Free} that works with containers of type constructors instead of the type constructors itself. 
In the following, we have a more detailed look at containers and how they relate to functors.

\subsection{First-Order Containers}
For a functor \cinl{F}, we define a first version of a container class that looks as follows.

\begin{minted}{Coq}
Class Container F :=
  {
    Shape   : Type;
    Pos     : Shape -> Type;
  }.
\end{minted}

The first component of a container is the type \mintinline{Coq}{Shape}.
A shape determines how the data type is structured, regardless of the stored values.
For example, the  shape of a list is the same as the shape of Peano numbers: a number that  represents the length of the list, or rather the number of \cinl{Cons}/\cinl{Succ} applications.
A pair, on the other hand, has only a single shape.

The second component of a container is a function \cinl{Pos : Shape -> Type} that gives each shape a type that represents the positions within the shape.
In the example of pairs, the shape has two positions, the first and second component.
Each element of a list is a position within the shape.
Therefore, the position type for lists with length $n$ is natural numbers smaller than $n$.
Peano numbers do not have elements and therefore, the position type for each shape is empty.

Containers can be extended by a function that maps all valid positions to values.
Since the position type depends on a concrete shape, the definition in Coq is quantified universally over values of type \cinl{Shape}.
In the following definition, \cinl{Shape} and \cinl{Pos} represent the components of a container as defined above.

\begin{minted}{Coq}
Inductive Ext Shape Pos A := 
| ext : forall s, (Pos s -> A) -> Ext Shape Pos A.
\end{minted}

The extension of a container is isomorphic to the original data type.
This means that we can define functions \cinl{to} and \cinl{from} that transform values of the container extension into values of the original data type and vice versa.
Additionally, proofs that show \cinl{to . from = id} and \hinl{from . to = id} as evidence of the isomorphism are required.
Thus, the \cinl{Container} class is extended by the transformation functions and the isomorphism proofs.

\begin{minted}{Coq}
Class Container F :=
  {
    Shape   : Type;
    Pos     : Shape -> Type;
    to      : forall A, Ext Shape Pos A -> F A;
    from    : forall A, F A -> Ext Shape Pos A;
    to_from : forall A (fx : F A), to (from fx) = fx;
    from_to : forall A (e : Ext Shape Pos A), from (to e) = e
  }.
\end{minted}

To gain a better understanding of how functors are represented using containers, the following subsection describes the general scheme for translating a functor into an isomorphic container\footnote{Often the container extension is meant when talking about containers. As described in the container class, only the extension of a container is isomorphic to the original data type but not the container alone.}.

\subsection{Modelling Functors as Containers}
As an example of modelling a functor as a container, we consider the non-determinism effect described in \autoref{subsec:effectHandlers}
The definition of the data type is simply translated from Haskell.

\begin{minted}{Coq}
  Inductive Choice (A : Type) :=
  | cfail   : Choice A
  | cchoice : option ID -> A -> A -> Choice A.
\end{minted}

When determining the shape of a functor, we first have to consider whether the data type is recursive.
For the effect data types, recursion is introduced by \cinl{Free}, so the types are generally non-recursive.
This means that we only need one shape for each constructor.

Next, we focus on the arguments of the constructors.
Since \cinl{cfail} has no arguments, there is no data that needs to be stored in its shape.
\cinl{cchoice}, however, has three arguments.
In the definition of the container extensions in the previous subsection, a function of type \cinl{forall s, Pos s -> A} was mentioned.
This function is responsible for all arguments of type \cinl{A} and thus, they are not part of the shape of the \cinl{cchoice} contructor.
All arguments of types other than \cinl{A}, that is, \cinl{option ID} in this case, become part of the shape.
This results in the following shape for the type \cinl{Choice}.

\begin{minted}{Coq}
  Inductive Shape__Choice :=
  | sfail : Shape__Choice
  | schoice : option ID -> Shape__Choice.
\end{minted}

The second component of a container is the function \cinl{Pos} that assigns each shape a position type.
This type describes all positions for values of type \cinl{A} in the constructor that the shape represents.
For the \cinl{cfail} constructor, there are no arguments (of type \cinl{A}).
This means that when \cinl{Pos} receives a shape \cinl{sfail}, a type that represents no positions needs to be returned.
Thus, the constructorless type \cinl{Inductive Void :=.} is returned.
On the other hand, \hinl{cchoice} contains two arguments of type \cinl{A} and thus, has two positions.
We could define a new type with two constructors, but for this simple task, \cinl{bool} works just as well.
Consequently, \cinl{true} means the first \cinl{A} position in \cinl{cchoice} and \cinl{false} the second one.

\begin{minted}{Coq}
Definition Pos__Choice (s: Shape__Choice) : Type :=
  match s with
  | sfail     => Void
  | schoice _ => bool
  end.
\end{minted}

With the definition of \cinl{Shape} and \cinl{Pos}, we can define the container extension type as follows.

\begin{minted}{Coq}
Definition Ext__Choice : Type -> Type := Ext Shape__Choice Pos__Choice.
\end{minted}

The transformation functions are a first indicator whether the definition of the shape and position types are correct.
When transforming a value of type \cinl{Choice}, we need to supply two arguments to the container extension constructor \cinl{ext}.
Firstly, the shape that corresponds to the constructor.
For \cinl{cfail} and \cinl{cchoice}, this is \cinl{sfail} and \cinl{schoice} respectively.
The latter takes the optional ID argument since this information cannot be stored in the second argument \cinl{ext}: the position function.
To construct such a function, we define a function \cinl{pf} that takes a position argument.
The type of the position is determined by \cinl{Pos} applied to the first argument of \cinl{ext}, that is, the shape that corresponds to the constructor that is currently handled.
Evaluating \cinl{Pos__Choice sfail} yields \cinl{Void}, so we need to return a value of type \cinl{A} for each constructor of the type.
Since \cinl{Void} does not have constructors, we do not need to return anything.
This is expressed in Coq by doing empty pattern matching on the position argument of the function.
The type of the position is known at compile time and thus, Coq accepts this definition.

\begin{minted}{Coq}
Fixpoint from__Choice A (z : Choice A) : Ext__Choice A :=
  match z with
  | cfail _     =>
    let pf (p : Pos__Choice sfail) := match p with end
    in ext sfail pf
  | cchoice mid l r =>
    let s := schoice mid
    in let pf (p : Pos__Choice s) := if p then l else r
       in ext s pf
  end.
\end{minted}

The position function in case of \cinl{cchoice} is slightly more involved.
This time, \cinl{Pos__Choice} returns \cinl{bool} as the type of the argument \cinl{p}.
Consequently, we need to return a value of type \cinl{A} for both members of the type \cinl{bool}.
Since \cinl{cchoice} has two such arguments, we just need to return the corresponding argument depending on whether \cinl{p} is \cinl{true} or \cinl{false}.

Based on this intuition of how the position function works, \cinl{to} can be defined easily.
We pattern match for the different shapes and create values using the corresponding constructors of the original data type.
This time, there is a position function \cinl{pf} given by the container extension.
Knowing the type of argument it expects, we use the function to retrieve the values of type \cinl{A}.

\begin{minted}{Coq}
 Definition to__Choice A (e: Ext__Choice A) : Choice A :=
    match e with
    | ext sfail         pf => cfail A
    | ext (schoice mid) pf => cchoice mid (pf true) (pf false)
    end.
\end{minted}

Finally, the remaining parts of the container definition are the isomorphism proofs.
The first proof is done by case distinction over the value \cinl{ox}.

\begin{minted}{Coq}
Lemma to_from__Choice : forall A (ox : Choice A),
                          to__Choice (from__Choice ox) = ox.
  Proof.
    intros A ox.
    destruct ox; reflexivity.
  Qed.
\end{minted}

In both cases, the transformation functions neither add nor remove information, as shown in the following for the \cinl{cchoice} constructor.

\begin{minted}{Coq}
  to__Choice (from__Choice (cchoice mid l r))
= let s := schoice mid
  in let pf (p : Pos__Choice s) := if p then l else r
     in to__Choice (ext s pf)
= let s := schoice mid
  in let pf (p : Pos__Choice s) := if p then l else r
     in cchoice mid (pf true) (pf false)
= cchoice mid l r
\end{minted}

The second proof is slightly more complicated than the first one.
Whereas we had to show the equality of two values of type \cinl{Choice} before, we now need to do the same for values of type \cinl{Ext__Choice}.
Since such values contain function arguments, we need to show function equality.

\begin{minted}{Coq}
Lemma from_to__Choice : forall A (e : Ext__Choice A),
  from__Choice (to__Choice e) = e.
Proof.
  intros A [s pf].
  destruct s; simpl; f_equal; extensionality p.
  - contradiction.
  - destruct p; reflexivity.
Qed. 
\end{minted}

After destructing the shape of \cinl{e} for a case distinction and simplifying the expression, we are in a situation where the goal is similar to \cinl{ext sfail pf = ext sfail pf'}.
The tactic \cinl{f_equal} states that two values are equal if both constructors are the same and all arguments are equal, too.
Since the constructor and first argument are equal, the only remaining goal is to prove that the position functions are equal.
The tactic \cinl{extensionality} is useful to show function equality, that is, $\forall x: f x = g x \implies f = g$.
The position \cinl{p} appears in the proof context with an appropriate type, which is determined by the function \cinl{Pos__Choice}.
There are two goals left to prove that correspond to the shapes of the container.
The first goal arises from \cinl{sfail} and looks as follows.

\begin{minted}{Coq}
A : Type
pf : Void -> A
p : Void
============================
match p return A with
end = pf p
\end{minted}

Since the position function for \cinl{sfail} takes arguments of type \cinl{Void}, there is a value \cinl{p} of type \cinl{Void} in the context.
However, this is not possible because \cinl{Void} has no constructors.
Consequently, the tactic \cinl{contradiction} solves this case.

For the second case that corresponds to the shape \cinl{schoice}, the position function takes arguments of type \cinl{bool}.

\begin{minted}{Coq}
A : Type
o : option ID
pf : bool -> A
p : bool
============================
(if p then pf true else pf false) = pf p
\end{minted}

If we destruct \hinl{p}, we can see that the \cinl{if}-statement returns \cinl{pf true} if \cinl{p} is \cinl{true} and vice versa, which leads to two trivially true equations.
This shows that the transformation functions form an isomorphism.
Therefore, strictly positive functors can be represented as container extensions.

Finally, the container instance can be defined as follows.

\begin{minted}{Coq}
  Instance C__Choice : Container Choice :=
    {
      to_from := to_from__Choice;
      from_to := from_to__Choice
    }.
\end{minted}

The isomorphism contains all necessary information about the container and its extension.
Thus, Coq is able to infer the omitted definitions.

\section{Modelling Effects}
\begin{itemize}
\item In which ways is the Coq implementation simplified, compared to Haskell?
\item How does the adapted Prog/sig infrastructure work?
\item How do we translate recursive functions?
\end{itemize}

In the previous section, a technique for representing functors as containers was presented.
The initial motivation for this was the issue of non-strictly positive occurrence errors in the definition of \cinl{Free}.
Since containers can only represent strictly positive functors, the following definition is accepted by Coq.

\begin{minted}{Coq}
Variable F : Type -> Type.

Inductive Free (C__F : Container F) A :=
| pure   : A -> Free C__F A
| impure : Ext Shape Pos (Free C__F A) -> Free C__F A.
\end{minted}

The parameter \cinl{F} is replaced by the container that represents \cinl{F}.
Instead of writing \cinl{F (Free F A)} as the first argument of \cinl{impure}, we can now use the extension of the container \cinl{C__F} applied to \cinl{Free C__F A}.

\subsection{Infrastructure}
\label{subsec:infrastructure}

With the \cinl{Free} data type defined, we can begin implementing the remaining infrastructure. 
In the Haskell implementation, various type classes and language extensions were used to make working with effects as comfortable as possible.
For the Coq implementation, the infrastructure is not implemented as generalized as before, but rather tailored to the purpose of modelling call-time choice.
This means, for example, that handlers do not work with arbitrary signatures where one part is a type variable.

\paragraph{Combining Effects}
Although it would be possible to merge all effects into one call-time choice effect with a large handler, the combination of independent effects is still a good idea in terms of modularity.
Thus, we need a counterpart to the functor \hinl{:+:} in Haskell.

The original functor is still parameterized over two functors \cinl{F} and \cinl{G} that represent effects.

\begin{minted}{Coq}
Variable F G : Type -> Type.

Inductive Comb A : Type :=
| Inl : F A -> Comb A
| Inr : G A -> Comb A.
\end{minted}

Since \cinl{Comb} combines effects into a new effect functor, we need to represent the combination as a container, too.
We assume that we have containers \cinl{C__F : Container F} and \cinl{C__G : Container G} for both functors.
The shape can then be defined as a \cinl{sum} type -- the Haskell equivalent is \hinl{Either} -- of the containers' shapes.

\begin{minted}{Coq}
Definition Shape__Comb : Type := sum (@Shape F C__F) (@Shape G C__G).
\end{minted}

The same principle applies to the function \cinl{Pos}.
The shape argument can be distinguished by means of the \cinl{sum} constructors \cinl{inl} and \cinl{inr}.
Depending on the \cinl{sum} constructor, the shape inside is passed to the \cinl{Pos} function of either \cinl{C__F} or \cinl{C__G}.

\begin{minted}{Coq}
Definition Pos__Comb (s : Shape__Comb) : Type :=
  match s with
  | inl x => @Pos F C__F x
  | inr x => @Pos G C__G x
  end.
\end{minted}

The transformation functions also depend on the functions defined in the containers for \cinl{F} and \cinl{G}.
To transform an \cinl{Ext__Comb} into a \cinl{Comb}, the \cinl{sum} constructor that wraps around the shape is removed and the original \cinl{to} function is called.
The result is then wrapped in a \cinl{Inl} or \cinl{Inr} constructor.
Transforming a \cinl{Comb} into an \cinl{Ext__Comb} is achieved by passing the value inside the \hinl{Comb} constructor to \cinl{from} and then wrapping a \cinl{sum} constructor around the shape of the result.

The isomorphism proofs work similar to the \cinl{Choice} proofs in regard to destructing values and shapes.
In addition, the isomorphism properties arising from $\texttt{C}_\texttt{F} \cong \texttt{F}$ and $\texttt{C}_\texttt{G} \cong \texttt{G}$ are applied.

\paragraph{Monad Operations}
In the Haskell monad instance for \hinl{Prog}, we used \hinl{fmap} to distribute a function throughout the structure determined by the functor argument.
Since the Coq implementation uses containers instead of functors, we need to define a function that behaves similar to \hinl{fmap}.
For this purpose, the function \cinl{cmap} is defined as follows.

\begin{minted}{Coq}
Variable F : Type -> Type.
Variable C__F : Container F.

Definition cmap A B (f : A -> B) (x : Ext Shape Pos A) 
  : Ext Shape Pos B :=
  match x with
  | ext s pf => ext s (fun x => f (pf x))
  end.
\end{minted}

Instead of an argument of type \cinl{F A} and an \cinl{F B} result, the corresponding container extension is used.
In order to behave like \hinl{fmap}, the function needs to apply the argument \cinl{f} to all values of type \cinl{A}.
The arguments are returned by the position function \cinl{pf}, so the new position function that returns values of type \cinl{B} is \cinl{f . pf}.

Based on this definition, we can defined bind for \cinl{Free}.
Although a direct definition would be possible, this can lead to issues with Coq's termination check in some situation.
Therefore, the function argument is introduced as a section variable.

\begin{minted}{Coq}
Variable A B: Type.
Variable f: A -> Free C__F B.

Fixpoint free_bind' (ffA: Free C__F A) :=
  match ffA with
  | pure x => f x
  | impure e => impure (cmap free_bind' e)
  end.
\end{minted}

The function is defined similar to the Haskell version.
Since \cinl{f} is a section variable instead of an argument of the function, \hinl{fmap (>>= f)} becomes \cinl{cmap free_bind'}.
Outside of the section, we can now define \cinl{free_bind} by flipping the argument order, so that the added function argument is moved to the usual position.
Using Coq's notation mechanism, we can define bind as an infix operator to keep the definitions similar to the Haskell implementation.

\begin{minted}{Coq}
Notation "mx >>= f" := (free_bind mx f)
                       (at level 50, left associativity).
\end{minted}

While we could define a monad type class and an instance for \cinl{Free}, this is omitted to simplify the implementation.
Consequently, instead of \hinl{return}, the function \cinl{pure} is used to create monadic values.

\paragraph{Effect Syntax}

In the Haskell implementation, the type class \hinl{:<:} was used to inject syntax into a program, that is, an appropriate nesting of the combination functor \hinl{:+:} was derived from the type context.
Contrary to that, the Coq implementation is based on a fixed effect stack that is handled in a predetermined  order.
Whereas we used \hinl{inject} to define effect syntax like the \hinl{get} operator, we now have to combine the effects manually.
Firstly, however, the state effect container is defined as an example of syntax constructors.

To avoid adding another type argument to all definitions, the type of the state is defined as a section variable \cinl{S}.

\begin{minted}{Coq}
Inductive State (A : Type) :=
| cget : (S -> A) -> State A
| cput : S -> A -> State A.
\end{minted}

The shape of the state container has two constructors that represent the constructors of \cinl{State}.
The function \cinl{S -> A} is not part of the shape because it returns a value of type \cinl{A}.
Thus, the position function is responsible for handling this argument.
For \cinl{sput}, the first argument carries the new state from the original constructor.

\begin{minted}{Coq}
Inductive Shape__State :=
| sget : Shape__State
| sput : S -> Shape__State.
\end{minted}

The function \cinl{Pos} returns either \cinl{S} or \cinl{unit}, depending on the given shape.
Since the function argument of \cinl{cget} returns a value of type \cinl{A} for every \cinl{S}, each value of \cinl{S} represents a position of the shape \cinl{sget}.
\cinl{cput} has only one argument of type \cinl{A} and thus, the type \cinl{unit} is returned.

\begin{minted}{Coq}
Definition Pos__State (s : Shape__State) : Type :=
  match s with
  | sget   => S
  | sput _ => unit
  end.
\end{minted}

The transformation functions are omitted here since this section is focused on effect syntax.
In order to define syntax for the state effect, we first need to define an effect stack.
The effect stack is constructed by means of the combination container and the effect containers that were defined in the previous section.
Similar to the Haskell implementation, the state effect -- with a pair of natural numbers as state -- should be handled first.
Therefore, it is the outermost effect.
The other argument of \cinl{C__Comb} is the combination of sharing and non-determinism, the former of which is defined in the next section.
 
\begin{minted}{Coq}
Definition NDShare := C__Comb (C__State (nat * nat)) 
                              (C__Comb C__Sharing C__Choice).
Definition Prog := Free NDShare.
\end{minted}

When \cinl{Free} is applied to \cinl{NDShare}, the resulting functor represents programs that are evaluated with respect to call-time choice.

With the effect stack in mind, we can begin defining syntax for the state effect.
The definition of the Haskell smart constructor for \hinl{get} is as follows.

\begin{minted}{Haskell}
get :: (State s :<: sig) => Prog sig s
get = inject (Get' return)
\end{minted}

In Coq, the definition is implemented by defining a value of the \cinl{NDShare} combination container.
Therefore, we need to supply a shape and a position function to the constructor \cinl{ext}.
The shape for \hinl{get} is \cinl{sget}.
However, \cinl{sget} is a shape of the state container but we need a combination shape for this definition to be correct.
Consequently, we use \cinl{inl} as a combination shape with \cinl{sget} as its argument.
In this case \cinl{inl} is used to select the left container argument of \cinl{NDShare}, which is the state container, as defined previously.

\begin{minted}{Coq}
Definition Get : Prog (nat * nat) :=
  let s : @Shape _ NDShare := inl sget
  in impure (ext s (fun p : @Pos _ NDShare s => pure p)).
\end{minted}

The position function takes arguments of type \cinl{@Pos _ NDShare (inl sget)}.
According to the definition of \cinl{Pos} for the combination container, the function \cinl{Pos} of the left container is applied to \cinl{sget}.
As defined above, the function \cinl{Pos__State} returns \cinl{S} or rather \cinl{nat * nat} for the shape \cinl{sget}.
Since we have a position \cinl{p : nat * nat} and need to return a value of type \cinl{Prog (nat * nat)}, applying \cinl{pure} to \cinl{p} yields the correct result.

The smart constructor for \hinl{put} works similar to \hinl{get}, with the difference that the new state is stored within the shape.
Furthermore, the return type is \cinl{Prog unit} because \hinl{put} has no information to return.
Thus, the position function, whose argument \cinl{p} has the type \cinl{unit} according to \cinl{Pos__State}, always returns \cinl{pure tt}.

\begin{minted}{Coq}
Definition Put (n : nat * nat) : Prog unit :=
  let s : @Shape _ NDShare := inl (sput n)
  in impure (ext s (fun p : @Pos _ NDShare s => pure tt)).
\end{minted}

For the other effects, the syntax smart constructors are defined similarly.
Since sharing and non-determinism are combined in the right argument of the \cinl{Comb} container, the shapes are wrapped in \cinl{inr}.
Then, the shape is wrapped again in \cinl{inl} or \cinl{inr}, depending on the position of the effect within the second combination container, as shown in the smart constructor for failed computations.

\begin{minted}{Coq}
Definition Fail A : Prog A :=
  let s : @Shape _ NDShare := inr (inr sfail)
  in impure (ext s (fun p : @Pos _ NDShare s => match p with end)).
\end{minted}

\subsection{Effect Stack and Handlers}
\label{subsec:effectstack}

With the definitions of effect and combination containers, smart constructors and the effect stack from the previous subsection, we can now discuss handlers.
\autoref{fig:effectStackHandling} visualizes the effect stack and how handlers remove effects one by one.

\begin{figure}[H]
{\centering \cinl{C__Comb (C__State (nat * nat)) (C__Comb C__Sharing C__Choice)} \par}

\hspace*{.48\textwidth} {\Large \boldmath $\downarrow$} \mintinline[fontsize=\scriptsize]{Coq}{runState}

{\centering \cinl{C__Comb C__Sharing C__Choice} \par}

\hspace*{.48\textwidth} {\Large \boldmath $\downarrow$} \mintinline[fontsize=\scriptsize]{Coq}{runSharing}

{\centering \cinl{C__Choice} \par}

\hspace*{.48\textwidth} {\Large \boldmath $\downarrow$} \mintinline[fontsize=\scriptsize]{Coq}{runChoice}

{\centering \cinl{Tree} \par}

\hspace*{.48\textwidth} {\Large \boldmath $\downarrow$} \mintinline[fontsize=\scriptsize]{Coq}{dfs}

{\centering \cinl{list} \par}
\caption{Effect Stack Handling}
\label{fig:effectStackHandling}
\end{figure}

Beginning with \cinl{NDShare}, the first handler \cinl{runState} handles the state effect and returns a program without state syntax.
Then, handlers for sharing and non-determinism handle the respective effects and a choice tree is returned.
The tree is then transformed into a list via depth-first search according to the algorithm presented in \autoref{subsec:effectHandlers}.

The differences between the Haskell and Coq implementation of handlers is shown using the example of the state effect handler.
The state handler was defined in \autoref{subsec:effectHandlers} as follows.

\begin{minted}{Haskell}
runState :: Functor f => s -> Prog (State s + f) a -> Prog f (s, a)
runState s (Return a) = return (s, a)
runState s (Get    k) = runState s (k s)
runState s (Put s' p) = runState s' p
runState s (Other op) = Op (fmap (runState s) op)
\end{minted}

Since Coq does not support language extensions like view patterns and pattern synonyms to simplify pattern matching, handlers are defined by matching plain \cinl{Prog} terms.
The Coq signature of the state effect handler describes the first step shown in \autoref{fig:effectStackHandling}, that is, the state effect is handled and a program that contains sharing and non-determinism is returned.
Since the state \hinl{s} of \hinl{(s,a)} was never used in the Haskell implementation, it is omitted in the Coq version.

\begin{minted}{Coq}
Fixpoint runState A (st : nat * nat) (p : Prog A) : Prog__SC A :=
  match p with
  | pure x => pure x
  | impure (ext (inl sget)       pf) => runState n (pf st)
  | impure (ext (inl (sput st')) pf) => runState st' (pf tt)
  | impure (ext (inr s) pf) => impure (cmap (runState st) (ext s pf))
  end.
\end{minted}

The constructors \hinl{Return} and \hinl{Op} correspond to \cinl{pure} and \cinl{impure}, respectively.
While the \hinl{Op} constructor was hidden in the pattern in Haskell, we now have to explicitly match for it.
Whereas in Haskell, the function \hinl{project} was used to unwrap the \hinl{Inl} and \hinl{Inr} constructors of \hinl{:+:}, the corresponding constructors are now determined by the effect stack and thus, can be matched explicitly.
In the combination tree, the state effect was the left argument.
Therefore, \cinl{inl s} matches both shapes \cinl{s} of the state container.
Similarly, \cinl{inr s} works the same as the \hinl{Other} pattern in Haskell.
In fact, the definition does not differ between both implementations.

The right-hand sides of the rules are slightly different in the Coq implementation due to the container structure.
Since the program argument is not part of the shape but stored in the position function, it is retrieved by applying \cinl{pf} to \cinl{s}.
This represents the continuation in the Haskell implementation, which is also applied to the current state.
For \cinl{sput}, the new state is set for the recursive call and \cinl{pf tt} returns the remaining program.

The last rule covers all other effect shapes in the right branch of the combination container, that is, sharing and non-determinism.
Since effects are represented as containers, we need to use \cinl{cmap} instead of \cinl{fmap}.
Furthermore, the \cinl{inr} wrapper is removed from the shape because \cinl{cmap} handles the sharing effect inside all programs that are stored by the position function.
Since the position function is parameterized over a shape, both must be compatible.

\section{Sharing}
\label{sec:lawsOfSharing}
For the implementation of the sharing effect in Coq, we first the implement explicit scoping tag approach.
Although the first-order handler of this approach has downsides that are discussed later in the section, it supports the same functionality as the Haskell implementation.
The higher-order approach would be suited much better in this regard.
Unfortunately, other problems arise from the higher-order definition and limit the applicability of the approach.
This is discussed in more detail in \autoref{sec:coqHO}.

We begin with the definition of the sharing container.
Similar to the Haskell implementation, the sharing functor has two constructors that open and close a scope.
Each constructor has an ID and an argument that later represents the remaining program.

\begin{minted}{Coq}
Inductive Sharing (A : Type) :=
| cbsharing : (nat * nat) -> A -> Sharing A
| cesharing : (nat * nat) -> A -> Sharing A.
\end{minted}

The corresponding container is easily defined according to the scheme presented in \autoref{subsec:infrastructure}.
The ID is stored in each constructors' shape and the argument of \cinl{A} means that each shape has one position.
Thus, the position function returns \cinl{unit} for both shapes.

\begin{minted}{Coq}
Inductive Shape__Sharing :=
| sbsharing : (nat * nat) -> Shape__Sharing
| sesharing : (nat * nat) -> Shape__Sharing.

Definition Pos__Sharing : Shape__Sharing -> Type := fun _ => unit.
\end{minted}

Similar to the Haskell implementation, the type classes \cinl{Shareable} an \cinl{Normalform} allow deep sharing and normalization of effectful expressions.
The normal form instance for lists requires inlining the \cinl{Share} operator because the termination checker does not accept the definition otherwise but the other definitions are similar to the Haskell implementation.
Combined with smart constructors for \cinl{begin} and \cinl{end}, we can implement the \cinl{Share} operator as follows.
Since Haskell's \hinl{do} notation is too complex for Coq's notation mechanism, we use explicit calls of bind instead.

\begin{minted}{Coq}
Definition Share A `(Shareable A) (fp : Prog A) : Prog (Prog A) :=
  Get >>= fun '(i,j) =>
  Put (i + 1, j) >>= fun _ =>
  pure (BeginShare (i,j) >>= fun _ =>
        Put (i, j + 1) >>= fun _ =>
        fp >>= fun x =>
        shareArgs x >>= fun x' =>
        EndShare (i,j) >>= fun _ =>
        pure x').
\end{minted}

The only remaining part of the sharing effect is the handler.
In the Haskell, the handler is implemented as a mutually recursive pair of functions that handle sharing inside and outside of a sharing scope.
Since Coq loads definitions sequentially, mutual recursion poses a problem when checking the function for termination.
Adding one function as an higher-order argument to the other does not convince Coq that the function terminates.
However, defining the "inside-scope" handler as a local definition using \cinl{let fix} works.
To keep the definition readable, the functions are discussed separately here.

\begin{minted}{Coq}
Fixpoint runSharing A (p: Prog__SC A) : Free C__Choice A :=
  match p with
  | pure x    => pure x
  | impure op =>
    match op with
    | ext (inl (sbsharing n))  pf => nameChoices 1 n [n] (pf tt)
    | ext (inl (sesharing n))  pf => runSharing (pf tt) (* error *)
    | ext (inr s) pf => impure (cmap (@runSharing A) (ext s pf))
    end
  end.
\end{minted}

The handler is largely the same as in Haskell with the exception of an additional argument \cinl{n} for \cinl{nameChoices}.
This value represents the head of the list of scopes, which is the following argument.
Since Coq only accepts total functions, the case of an empty scope context -- which can never occur because the inner handler is called with a non-empty scope and because it returns as soon as the last scope has been closed -- would need to be handled cumbersomely.
Thus, the invariant of a non-empty list is enforced by a separate head element.

There is, however, an issue with the rule for \cinl{sesharing}.
Since the shape represents an ending tag in the outside-scope handler, an error is thrown in the corresponding rule of the Haskell implementation.
Although it is impossible to construct a faulty program by only using the \cinl{Share} operator and not the scope tags individually, these cases need to be handled.
There are two options: Firstly, the return type could be made optional, so that error cases return no result.
This is, however, not an ideal solution because it would entail that we always have to reason about optional values in proofs.
A more practical approach is to ignore mismatched tags and to continue handling the remaining program that is associated with the tag.
While this approach is still not ideal, it is the most practical solution to this problem.

The function \cinl{nameChoices} has the same issue where a closing tag with an ID different than the current scope might occur.
This situation is handled the same way as in \cinl{runSharing}.
When a choice is encountered, an ID is assigned based on the current scope and scope counter, as seen in the Haskell implementation.

An alternative solution to the problem of handling mismatched tags is the higher-order approach discussed in \autoref{sec:coqHO}.
First, however, a few examples that demonstrate the functionality of the Coq implementation are discussed in the next section.

\section{Examples}
Coq is a strict language without native support for non-determinism.
Although the latter is also true for Haskell, non-strictness is part of Haskell's evaluation strategy.
Thus, examples that feature non-strict non-determinism are far more interesting in Coq because the non-strictness can be attributed solely to the model.
For this reason, the first example is the function \hinl{recList}, which negates the head of a list and then adds either the original tail \hinl{ys} of the list of the list returned by a recursive call of \hinl{recList} applied to \hinl{ys}.
This function can be defined in Curry as follows. 

\begin{minted}{Haskell}
recList :: [Bool] -> [Bool]
recList xs = case xs of
               []     -> []
               y : ys -> not y : (ys ? recList ys)
\end{minted}

To translate this function to the Haskell model, we use the lifted list type and replace pattern matching with bind.

\begin{minted}{Haskell}
recList :: (Sharing m, MonadPlus m) 
        => m (List m Bool) -> m (List m Bool)
recList fxs = fxs >>= \xs ->
  case xs of
    Nil         -> nil
    Cons fy fys -> cons (notM fy) (fys `mplus` recList fys)
\end{minted}

One could expect that the same definition -- apart from syntactical differences -- works in Coq.
Unfortunately, this is not the case.
The termination check throws an error because it is not obvious that \hinl{fys} is a structurally smaller than \hinl{fxs}.
A technique proposed by \citet{christiansen2018oneMonad} works by splitting a recursive function into two definitions, where one is recursive but takes plain values instead of \cinl{Prog} arguments and the other is a simple definition that contains the first call of bind.

\begin{minted}{Coq}
Fixpoint recList' (xs : List bool) : Prog (List bool) :=
  match xs with
  | Nil' => nilM
  | Cons' fy fys => consM (notM fy)
                         (fys ? fys >>= fun zs => recList' zs)
  end.

Definition recList (fxs : Prog (List bool)) : Prog (List bool) :=
  fxs >>= fun xs => recList' xs.
\end{minted}

This adapted definition entails that the recursive call of \hinl{recList'} cannot work with the argument \cinl{fys} directly, but instead needs to be called as an argument of bind.
However, since there is pattern matching over the function's argument, Coq accepts the new definition.

To test non-strict evaluation of non-determinism in the Coq model, we consider the expression \hinl{recList [True, False]}.
Evaluating the expression by itself is not very interesting because the expression is fully evaluated.
When the result is only partially demanded, for example with \cinl{head}, the interplay of non-strictness and non-determinism becomes visible.
In the following, a few examples with \hinl{T} and \hinl{F} as Boolean constructors are evaluated Curry and Coq.

We begin with an example that shows that non-strictness is preserved in the Coq model.
The following shows the application of \cinl{head} to \cinl{recList [T, F]}.

\begin{minted}{Haskell}
  head $ recList [T, F]
= head $ not T : ([F] ? recList [F])
= F
\end{minted}

Since \hinl{head} does not evaluate the tail of its list argument, no non-determinism is introduced and only the negation of the first element is returned.
In Coq, the expression evaluates to the same result.
Because the term is simple enough, it is not necessary to handle the program as it can be viewed as a \cinl{Prog} value.

\begin{minted}{Coq}
Compute (headM (recList (consM T (consM F nilM)))).
     = pure F
     : Prog bool
\end{minted}

The next example shows how non-determinism is only introduced as demanded.
Instead of applying \hinl{head} to the expression directly, \hinl{tail} is applied first.

\begin{minted}{Haskell}
  head $ tail (recList [T, F])
= head $ tail (not T : ([F] ? recList [F]))
= head $ [F] ? recList [F]
= head [F] ? head (recList [F])
= F ? head (not F : ([] ? recList []))
= F ? T
\end{minted}

The expression now evaluates to two results due to the choice introduced by evaluating \hinl{recList} once.
The Coq \cinl{Prog} term quickly grows in size, so it is handled and thus represented as a list of results.

\begin{minted}{Coq}
Compute handle (headM (tailM (recList (consM T (consM F nilM))))).
     = [F; T]
     : list bool
\end{minted}

Again, the Coq implementation yields the correct result.
The position of bind in \cinl{recList'} is essential for preserving non-strictness.
If bind was moved to the root of the expression, the tail of the list would be evaluated even if only the head is demanded.
For example, the following expression would not return the value expected value, but fail instead, because \cinl{Fail} is evaluated.

\begin{minted}{Coq}
Compute handle (headM (recList (consM T Fail))).
     = [F]
     : list bool
\end{minted}

For this reason, it is necessary to move calls of bind as close as possible to the position where the value is needed.
This is especially important if there are \cinl{case} or \cinl{if} branches where the bound value is not needed.

\section{Modelling Effects using Higher-Order Containers}
\label{sec:coqHO}

The first-order approach of modelling effects shown in this chapter allows representing scoped effects only with explicit scope delimiters.
In the last chapter, a higher-order approach was briefly discussed in \autoref{subsec:HOscopesyntax} as an alternative way to define scopes without explicit delimiters.
Due to the more abstract definition and the function arguments in the term structure, it was not suitable for discussing the different aspects of the sharing implementation.
However, with the prospect of avoiding mismatched scope tags being a tangible benefit, it seems worthwhile to pursue this approach in Coq.

\subsection{Higher-Order Containers}
\label{subsec-higherOrderContainers}
In the higher-order approach, effect signatures are represented not as a simple functor, but as as higher-order functor of type \hinl{(* -> *) -> * -> *}.
Similar to the first-order data type for \hinl{Prog}, the following higher-order version fails due to non-strictly positive occurrence of \cinl{Free}.

\begin{minted}{Coq}
Fail Inductive Free F A :=
| pure : A -> Free F A
| impure : F (Free F) A -> Free F A.
\end{minted}

This calls for a higher-order container that is able to represent higher-order functors.
Initially, one could assume that we can adapt the first-order container by replacing the functor \cinl{F} with the higher-order functor \cinl{H} and adding the necessary functor arguments of \cinl{H} to the list of quantified variables, as follows.

\begin{minted}{Coq}
Class HContainer (H : (Type -> Type) -> Type -> Type) :=
  {
    Shape   : Type;
    Pos     : Shape -> Type;
    to      : forall F A, Ext Shape Pos F A -> H F A;
    from    : forall F A, H F A -> Ext Shape Pos F A;
    to_from : forall F A (fx : H F A), to (from fx) = fx;
    from_to : forall F A (e : Ext Shape Pos F A), from (to e) = e
  }.
\end{minted}

The extension of such a higher-order container needs to be adapted, too.
Similar to higher-order functor data types, such as choice, the additional type variable \hinl{m :: * -> *} needs to be represented in the container.
Thus, it is added as a parameter to the container extension.
Since higher-order data types like choice have arguments of type \hinl{m a}, it seems appropriate to adapt the type of the position function to return values of type \cinl{F A}.

\begin{minted}{Coq}
Inductive Ext Shape (Pos : Shape -> Type) (F : Type -> Type) A := 
  ext : forall s, (Pos s -> F A) -> Ext Shape Pos F A.
\end{minted}

With the adapted higher-order container, we can now represent higher-order with a version of \cinl{Free} that works with higher-order containers.
For the additional functor argument, we can use \cinl{Free C}, similar to the Haskell implementation.

\begin{minted}{Coq}
Variable H : (Type -> Type) -> Type -> Type.

Inductive Free (C : HContainer H) A :=
| pure   : A -> Free C A
| impure : Ext Shape Pos (Free C) A -> Free C A.
\end{minted}

With the adapted definition of \cinl{Free}, it is possible to define containers for the effects non-determinism, state and combination.
The containers look almost identical to the original definitions because whenever the argument \cinl{A} occurred in the first-order data type, we can now use \cinl{F A} in the higher-order definition.
This also applies to the definition of containers.
However, one effect is missing from the above list: sharing.
Since the sharing effect can be defined without explicit scope delimiters in the higher-order implementation, we need to rethink its container.
In the Haskell implementation, the definition of the higher-order sharing functor is as follows.

\begin{minted}{Haskell}
data HShare m a = forall x. Share' (Int, Int) (m x) (x -> m a)
\end{minted}

Compared to the other effects, the argument \hinl{m x} is difficult to represent because the position function usually only handles values of type \hinl{m a}.
Thus, the corresponding container would need to store the ID, a value of type \hinl{m x} and the type \hinl{x} in its single shape.
The position function returns the type that is stored inside the shape, because for each \hinl{x}, the function argument \hinl{x -> m a} returns a value of type \hinl{m a}.

\begin{minted}{Coq}
Inductive Shape__Sharing (F : Type -> Type) :=
| ssharing : forall X, nat * nat -> F X -> Shape__Sharing F.

Definition Pos__Sharing F (s : Shape__Sharing F) : Type :=
  let '(@ssharing _ X _ _) := s in X.
\end{minted}

This definition is isomorphic to the original data type but it does not fit the container class because the shape -- and consequently the position function -- need to be parameterized over the functor \hinl{m} in order to store a value of type \hinl{m x}.
Although the container can be adapted to allow another parameter for \cinl{Shape} and \cinl{Pos}, this approach ultimately fails when defining \cinl{Free}.
The additional functor argument is instantiated with \cinl{Free C}, just like the regular functor argument \cinl{Ext}.
However, this moves \cinl{Free} to a possibly non-strictly positive position and thus, is not accepted by Coq.

\subsection{Indexed Containers}
The search\footnote{Thanks to Li-yao Xia for referring to indexed containers as a solution to this problem on stackoverflow.com, \url{https://stackoverflow.com/a/54892792/11112994}} for a container definition that is powerful enough to represent the sharing effect while preserving strict positivity leads to the concept of \textit{indexed containers}, introduced by \citet{altenkirch2009indexed}. 
The main difference between ordinary and indexed containers is an additional context function \cinl{Ctx} that determines the return type of the position function.
Instead of the fixed type \hinl{F A}, the parameter \cinl{A} is determined by the context function.
The context thus becomes part of the container, as shown below.

\begin{minted}{Coq}
Class HContainer :=
  {
    Shape   : Type;
    Pos     : Shape -> Type;
    Ctx     : forall s : Shape, Pos s -> Type -> Type
  }.
\end{minted}

The definition of \cinl{Ext} is adapted by adding a position parameter to the position function and replacing \cinl{A} with \cinl{Ctx s p A}.
Since the context function has \cinl{A} as a parameter, higher-order functors where \hinl{m} occurs only as \hinl{m a} can be represented before by defining \cinl{Ctx} as a constant function that returns \cinl{A}.
 
\begin{minted}{Coq}
Inductive Ext (C : HContainer) (F : Type -> Type) A :=
  ext : forall s, (forall p : Pos s, F (Ctx s p A)) -> Ext C F A.
\end{minted}

The new definition of the position function means that we no longer have to store a value of type \cinl{F X} as part of the shape.
Therefore, the shape does not need to be parameterized over \cinl{F}.
The type \cinl{X} is still part of the shape, nevertheless, since the sharing effect makes use of the context function and the type returned by \cinl{Ctx} needs to be part of one of its arguments.

\begin{minted}{Coq}
Inductive Shape__Sharing :=
| ssharing : nat * nat -> Type -> Shape__Sharing.
\end{minted}

The position type is now defined as an inductive definition because an additional argument of type \cinl{shapeType s}, that is, the quantified type \cinl{X}, is part of the constructor \cinl{pcont}.
Consequently, this covers all values of type \cinl{F A} that can be generated by the function argument of \cinl{ssharing}.
The position of other argument of type \cinl{F X} is represent by \cinl{pshared}.

\begin{minted}{Coq}
Inductive Pos__Sharing (s : Shape__Sharing) : Type :=
| pshared : Pos__Sharing s
| pcont   : shapeType s -> Pos__Sharing s.
\end{minted}

Finally, the context function is defined.
For the shared program, the context needs to return the type \cinl{X} so that the position function yields a value of type \cinl{F X}.
The type \cinl{X} is stored in the shape and thus, is retrieved using \cinl{shapeType}.
Since remaining program returns values of type \cinl{A}, the context function does so, too.

\begin{minted}{Coq}
Definition Ctx__Sharing (s : Shape__Sharing) (p : Pos__Sharing s) : Type -> Type :=
  match p with
  | pshared _ => fun _ => shapeType s
  | pcont _ _ => fun A => A
  end.
\end{minted}

The above definition of the sharing container is isomorphic to the original data type.
Furthermore, indexed containers do not require a parameterized shape or \cinl{Pos} function, which was the reason why the first definition of higher-order containers in \autoref{subsec-higherOrderContainers} failed.
Consequently, we can use the same definition of \cinl{Free} as shown in the last subsection.

Although we are now able to represent all necessary effects as containers and have a container definition that is strictly positive when used with \cinl{Free}, the higher-order implementation is still not as powerful as the first-order version.
Considering what is important for writing programs with the syntax we defined, the aspect of combining programs comes to mind.
In the first-order Coq implementation, we defined the function \cinl{free_bind} in order to use the same monadic structure from the Haskell version.
One important part of the definition of \cinl{free_bind} was \cinl{cmap}, the container-equivalent of \cinl{fmap}.
We begin constructing the definition of \cinl{cmap} using proof mode as follows.

\begin{minted}{Coq}
Definition cmap A B F (f : F A -> F B) (x : Ext Shape Pos Ctx F A) 
    : Ext Shape Pos Ctx F B.
  destruct x as [sh pf].
  apply ext with (s := sh).
  intros.
\end{minted}

At this point in the proof, the new position function is defined.
The context, as shown in the following, contains the position function \cinl{pf} from the container extension that was destructed and the position argument \cinl{p} from the new function, as well as the function \cinl{f} that we can use to turn values of type \cinl{F A} into \cinl{F B}.

\begin{minted}{Coq}
A, B : Type
F : Type -> Type
f : F A -> F B
sh : Shape
pf : forall p : Pos sh, F (Ctx sh p A)
p : Pos sh
============================
F (Ctx sh p B)
\end{minted}

The context function allows us to store values of different types in the position function.
Although this allowed us to define the sharing container and works well with \cinl{Free}, it becomes problematic now.
In the proof, we have variables \cinl{sh} and \cinl{p} that represent arbitrary shapes and positions, respectively.
Thus, we have no way of knowing whether the context function returns \cinl{A} or a different type and cannot apply the function \cinl{f}.
Since \cinl{cmap} is essential for defining bind over \cinl{Free}, the idea of a context that can either return \cinl{A} or any other type is not feasible.
There is, however, a solution to this problem, as presented in the next subsection.

\subsection{Indexed Bi-Containers}
The previous subsections have shown that both the naive higher-order container definition and indexed containers are not sufficient to model the higher-order Haskell implementation.
Whereas the naive version can reuse the first-order definition of \cinl{cmap} but does not work with \cinl{Free}, indexed containers harmonize with \cinl{Free} but \cinl{cmap} cannot be defined.
Based on this observation, a combination of both container definitions would be ideal.

A bi-container, as defined by \citet{ghani2007higherDimensional}, consists of two containers that use the same shape but have different \cinl{Pos} and position functions.
Applied to the topic of higher-order containers, this means that we split \cinl{Pos} into two functions: The first function behaves like the naive higher-order \cinl{Pos} function and the second one is used in conjunction with the context.
The definition of a higher-order container is adapted as follows.

\begin{minted}{Coq}
Class HContainer :=
  {
    Shape   : Type;
    Pos     : Shape -> Type;
    PosX    : Shape -> Type;
    Ctx     : forall s : Shape, PosX s -> Type;
  }.
\end{minted}

A container extension now has two position functions.
The first one handles values of type \cinl{F A}, whereas the second one returns values of a type that is determined by the context.
Since \cinl{F A} is handled by the first function, the context no longer needs the parameter \cinl{A}.

\begin{minted}{Coq}
Inductive Ext (C : HContainer) (F : Type -> Type) A :=
  ext : forall s, 
    (Pos s -> F A) -> (forall p : PosX s, F (Ctx s p)) -> Ext C F A.
\end{minted}

This definition allows us to define \cinl{cmap} similar to the first-order version.
The first position function returns only values of type \cinl{F A} and therefore can be mapped over, while the second position function does not contain \cinl{A} and thus, does not need to be changed.
In addition, the shape and \cinl{Pos} functions still do not need additional arguments.
Hence, the indexed bi-container definition works with \cinl{Free}.

With the new approach of higher-order containers, we can define the sharing effect one last time.
The shape remains the same as before with an ID and type argument.
For \cinl{Pos} and \cinl{PosX}, the constructors of the inductive data type are split.
Whereas \cinl{pcont} with its argument of type \cinl{shapeType s} is represented directly by the same type in \cinl{Pos__Sharing}, the single position of \cinl{pshared} is now handled by \cinl{PosX__Sharing} as follows.

\begin{minted}{Coq}
Definition Pos__Sharing (s : Shape__Sharing) := shapeType s.

Definition PosX__Sharing : Shape__Sharing -> Type := fun _ => unit.

Definition Ctx__Sharing (s : Shape__Sharing) : PosX__Sharing s -> Type :=
  fun _ => shapeType s.
\end{minted}

The context no longer distinguishes between positions and always returns the type that is stored in the shape argument, since the case of \cinl{A} as a return type is now handled by the other position function.
Converting between container extension and original data type is straight-forward.
The former direction calls the position functions with appropriate arguments to retrieve the values of the original constructor, while the latter one positions these values inside the position functions.

Now that we are finally able to represent all effects as higher-order containers and can use these containers with \cinl{Free} and bind for \cinl{Free}-based programs, we are able to adapt the remainder of the code base.
For the most part, the differences between first-order and higher-order are negligible and can be implemented by adding the additional position function of \cinl{ext} to patterns and expressions.

The adapted code works flawlessly for programs with primitive result types and result types that contain the lifted pair data type.
There is, however, a problem when it comes to lifted, recursive data types like lists.
In the following, \cinl{Prog} is defined as \cinl{Free NDShare} where \cinl{NDShare} is the effect stack defined in \autoref{subsec:effectstack}.

\begin{minted}{Coq}
Fail Inductive List A :=
| Nil  : List A
| Cons : Prog A -> Prog (List A) -> List A.
\end{minted}

Coq does not accept this definition due to non-strict occurrence of \cinl{List} in the second constructor.
Unfortunately, it is not obvious why this definition is rejected by Coq.
For each part of the definitions of \cinl{Free} and \cinl{Ext}, there is a constellation where \cinl{List} can be defined without errors.
The non-strictly positive occurrence error can also be evidence for \textit{truly nested} data types like the type \hinl{Bush} introduced by \citet{bird1998nested}.

\begin{minted}{Haskell}
data Bush a = NilB | ConsB (a, Bush (Bush a))
\end{minted}

Such nested self-applications are not allowed in Coq, which might be why the definition of \cinl{List} fails.

It is possible to circumvent this error by defining the data type using continuation passing style, that is, the list argument is encoded in a function that returns the list's tail after being applied to some value.

\begin{minted}{Coq}
Inductive List A :=
| Nil' : List A
| Cons' {T : Type} : Prog A -> Prog T -> (T -> List A) -> List A.
\end{minted}

While this definition is accepted by Coq, we do not gain much because we cannot define other crucial functions due to inconsistent universes and other error related to Coq's type hierarchy.

In conclusion, the higher-order approach is an elegant solution the problem of mismatched syntax delimiters and can be implemented in Coq using indexed bi-containers.
Although it is ultimately not possible to define recursive data type definitions with the resulting \cinl{Prog} data type, it is not clear whether there is a fundamental issue with the approach or if Coq's termination check is too restrictive in this case.
Nevertheless, the examples that do not feature recursive data types inspire confidence that the higher-order implementation of call-time choice is Coq works correctly, just like the fully functional first-order version.

\chapter{Curry Programs modelled in Coq}
\begin{itemize}
\item Can we use the Coq model of call-time choice to prove properties about actual Curry programs?
\end{itemize}

\chapter{Conclusion}

% Literatur
\bibliographystyle{plainnat}
\bibliography{Mathesis} % Datei: seminar.bib
% Anhang
\appendix
\end{document}